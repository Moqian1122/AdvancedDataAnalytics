{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "55332a9e-fbdd-4a54-9369-12ba7335b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import re\n",
    "\n",
    "#Every 6 hours I update this, create a new dataframe and append it/store it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bfdea139-4add-4e19-9db2-3ef5c17c0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dir = 'C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "312d0b90-6473-4a89-82c7-442c620b17c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = [file for file in os.listdir(json_dir) if file.endswith('.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a3605bcd-d3d6-46cd-902b-bc84eed79102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00000-00b1d078-e455-429f-ba5a-f07f653a8040-c000.json\n",
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00000-2802f6fb-efc5-4d8f-a334-0fd2413894e8-c000.json\n",
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00000-5aabdfb9-3924-4952-9b5f-1a1e55ff081e-c000.json\n",
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00000-6bc2e501-129c-4444-be35-19f932172608-c000.json\n",
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00000-6ddb0235-8fdf-4ead-996c-263356ac245b-c000.json\n",
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00000-95ec7b65-970b-4c03-9cd0-756258ac44a6-c000.json\n",
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00000-b7e54708-5370-4cf5-9fae-4a2ef32d5d9e-c000.json\n",
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00000-bf86f0ba-395e-4878-a8c0-9357de985dfd-c000.json\n",
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00000-f4f58945-864e-45a9-af83-2a75ed7f5da1-c000.json\n",
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00000-fff91172-df37-4fc8-9bdd-9cd4d01a29ff-c000.json\n",
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00001-00b1d078-e455-429f-ba5a-f07f653a8040-c000.json\n",
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00001-6ddb0235-8fdf-4ead-996c-263356ac245b-c000.json\n",
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00001-b7e54708-5370-4cf5-9fae-4a2ef32d5d9e-c000.json\n",
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00001-f4f58945-864e-45a9-af83-2a75ed7f5da1-c000.json\n",
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00002-f4f58945-864e-45a9-af83-2a75ed7f5da1-c000.json\n",
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00003-f4f58945-864e-45a9-af83-2a75ed7f5da1-c000.json\n",
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00004-f4f58945-864e-45a9-af83-2a75ed7f5da1-c000.json\n",
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00005-f4f58945-864e-45a9-af83-2a75ed7f5da1-c000.json\n",
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00006-f4f58945-864e-45a9-af83-2a75ed7f5da1-c000.json\n",
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00007-f4f58945-864e-45a9-af83-2a75ed7f5da1-c000.json\n",
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00008-f4f58945-864e-45a9-af83-2a75ed7f5da1-c000.json\n",
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00009-f4f58945-864e-45a9-af83-2a75ed7f5da1-c000.json\n",
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00010-f4f58945-864e-45a9-af83-2a75ed7f5da1-c000.json\n",
      "Error decoding JSON in file: C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/data\\part-00011-f4f58945-864e-45a9-af83-2a75ed7f5da1-c000.json\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the data from each JSON file\n",
    "json_data = []\n",
    "for file in json_files:\n",
    "    with open(os.path.join(json_dir, file), 'r') as f:\n",
    "        try:\n",
    "            data = json.load(f)\n",
    "            json_data.append(data['value'])\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON in file: {os.path.join(json_dir, file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0afa3bd0-35ea-4ab0-8a3e-9ebe99605028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each string representation into a dictionary\n",
    "data_dicts = [json.loads(data_str) for data_str in json_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4fc66c5f-08d3-40cc-ad7f-2180bb52dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_dicts)\n",
    "df['posted_at'] = df['posted_at'].apply(lambda x : datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "final_df = df.sort_values(by = 'posted_at', ascending = True).reset_index(drop = True)\n",
    "final_df = final_df.drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8f21a216-0272-434c-b624-2b2302d852ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aid</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>domain</th>\n",
       "      <th>votes</th>\n",
       "      <th>user</th>\n",
       "      <th>posted_at</th>\n",
       "      <th>comments</th>\n",
       "      <th>source_title</th>\n",
       "      <th>source_text</th>\n",
       "      <th>frontpage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40038747</td>\n",
       "      <td>Le Rôle de l'IA dans l'Évolution de l'Enseigne...</td>\n",
       "      <td>https://www.rubybiscuit.fr/p/hors-serie-6-trad...</td>\n",
       "      <td>rubybiscuit.fr</td>\n",
       "      <td>1</td>\n",
       "      <td>dom_fr</td>\n",
       "      <td>2024-04-15 10:39:26</td>\n",
       "      <td>0</td>\n",
       "      <td>[HORS SÉRIE #6] Tradition ou Transformation ? ...</td>\n",
       "      <td>[HORS SÉRIE #6] Tradition ou Transformation ? ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40038755</td>\n",
       "      <td>After delay due to xz, Ubuntu 24.04 'Noble Num...</td>\n",
       "      <td>https://www.theregister.com/2024/04/15/ubuntu_...</td>\n",
       "      <td>theregister.com</td>\n",
       "      <td>1</td>\n",
       "      <td>lproven</td>\n",
       "      <td>2024-04-15 10:40:57</td>\n",
       "      <td>0</td>\n",
       "      <td>Ubuntu 24.04 'Noble Numbat' belatedly hits beta</td>\n",
       "      <td>Ubuntu 24.04 'Noble Numbat' belatedly hits bet...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40038759</td>\n",
       "      <td>Weird monitor bugs people sent me in the last ...</td>\n",
       "      <td>https://notes.alinpanaitiu.com/Weird-monitor-bugs</td>\n",
       "      <td>alinpanaitiu.com</td>\n",
       "      <td>1</td>\n",
       "      <td>fanf2</td>\n",
       "      <td>2024-04-15 10:42:04</td>\n",
       "      <td>0</td>\n",
       "      <td>Weird monitor bugs people sent me in the last ...</td>\n",
       "      <td>Weird monitor bugs people sent me in the last ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40038860</td>\n",
       "      <td>SQL Optimizations in PostgreSQL: IN vs. Exists...</td>\n",
       "      <td>https://www.percona.com/blog/sql-optimizations...</td>\n",
       "      <td>percona.com</td>\n",
       "      <td>2</td>\n",
       "      <td>tie-in</td>\n",
       "      <td>2024-04-15 10:56:16</td>\n",
       "      <td>0</td>\n",
       "      <td>SQL Optimizations in PostgreSQL: IN vs EXISTS ...</td>\n",
       "      <td>SQL Optimizations in PostgreSQL: IN vs EXISTS ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40038882</td>\n",
       "      <td>Marques Brownlee on Humane AI Pin: The Worst P...</td>\n",
       "      <td>https://www.youtube.com/watch?v=TitZV6k8zfA</td>\n",
       "      <td>youtube.com</td>\n",
       "      <td>1</td>\n",
       "      <td>latexr</td>\n",
       "      <td>2024-04-15 10:59:33</td>\n",
       "      <td>0</td>\n",
       "      <td>The Worst Product I've Ever Reviewed... For Now</td>\n",
       "      <td>The Worst Product I've Ever Reviewed... For No...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>40232386</td>\n",
       "      <td>An inside look at General Motors' gamble in di...</td>\n",
       "      <td>https://9to5mac.com/2024/05/01/general-motors-...</td>\n",
       "      <td>9to5mac.com</td>\n",
       "      <td>4</td>\n",
       "      <td>mgh2</td>\n",
       "      <td>2024-05-02 03:25:34</td>\n",
       "      <td>0</td>\n",
       "      <td>An inside look at General Motors' massive gamb...</td>\n",
       "      <td>An inside look at General Motors' massive gamb...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>40232416</td>\n",
       "      <td>Pipelines for .NET Using GitHub Actions</td>\n",
       "      <td>https://alexandrehtrb.github.io/posts/2024/04/...</td>\n",
       "      <td>alexandrehtrb.github.io</td>\n",
       "      <td>1</td>\n",
       "      <td>thunderbong</td>\n",
       "      <td>2024-05-02 03:31:52</td>\n",
       "      <td>0</td>\n",
       "      <td>Pipelines for .NET - AlexandreHTRB blog</td>\n",
       "      <td>Pipelines for .NET - AlexandreHTRB blog\\n\\nPip...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>40232423</td>\n",
       "      <td>Volcker's Announcement of Anti-Inflation Measures</td>\n",
       "      <td>https://www.federalreservehistory.org/essays/a...</td>\n",
       "      <td>federalreservehistory.org</td>\n",
       "      <td>2</td>\n",
       "      <td>neom</td>\n",
       "      <td>2024-05-02 03:32:39</td>\n",
       "      <td>0</td>\n",
       "      <td>Volcker's Announcement of Anti-Inflation Measures</td>\n",
       "      <td>Volcker's Announcement of Anti-Inflation Measu...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>40232448</td>\n",
       "      <td>The long, ever faster decline of machining ski...</td>\n",
       "      <td>https://twitter.com/tuckergoodrich/status/1785...</td>\n",
       "      <td>twitter.com/tuckergoodrich</td>\n",
       "      <td>4</td>\n",
       "      <td>barry-cotter</td>\n",
       "      <td>2024-05-02 03:37:50</td>\n",
       "      <td>3</td>\n",
       "      <td>X</td>\n",
       "      <td>X\\n\\nDon’t miss what’s happening\\n\\nPeople on ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>40232466</td>\n",
       "      <td>A Knight's Tale</td>\n",
       "      <td>https://blogs.bl.uk/digitisedmanuscripts/2024/...</td>\n",
       "      <td>blogs.bl.uk</td>\n",
       "      <td>1</td>\n",
       "      <td>pepys</td>\n",
       "      <td>2024-05-02 03:40:18</td>\n",
       "      <td>0</td>\n",
       "      <td>Just a moment...</td>\n",
       "      <td>Just a moment...\\n\\n# blogs.bl.uk\\n\\n## Verify...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4007 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           aid                                              title  \\\n",
       "0     40038747  Le Rôle de l'IA dans l'Évolution de l'Enseigne...   \n",
       "1     40038755  After delay due to xz, Ubuntu 24.04 'Noble Num...   \n",
       "2     40038759  Weird monitor bugs people sent me in the last ...   \n",
       "3     40038860  SQL Optimizations in PostgreSQL: IN vs. Exists...   \n",
       "4     40038882  Marques Brownlee on Humane AI Pin: The Worst P...   \n",
       "...        ...                                                ...   \n",
       "4002  40232386  An inside look at General Motors' gamble in di...   \n",
       "4003  40232416            Pipelines for .NET Using GitHub Actions   \n",
       "4004  40232423  Volcker's Announcement of Anti-Inflation Measures   \n",
       "4005  40232448  The long, ever faster decline of machining ski...   \n",
       "4006  40232466                                    A Knight's Tale   \n",
       "\n",
       "                                                    url  \\\n",
       "0     https://www.rubybiscuit.fr/p/hors-serie-6-trad...   \n",
       "1     https://www.theregister.com/2024/04/15/ubuntu_...   \n",
       "2     https://notes.alinpanaitiu.com/Weird-monitor-bugs   \n",
       "3     https://www.percona.com/blog/sql-optimizations...   \n",
       "4           https://www.youtube.com/watch?v=TitZV6k8zfA   \n",
       "...                                                 ...   \n",
       "4002  https://9to5mac.com/2024/05/01/general-motors-...   \n",
       "4003  https://alexandrehtrb.github.io/posts/2024/04/...   \n",
       "4004  https://www.federalreservehistory.org/essays/a...   \n",
       "4005  https://twitter.com/tuckergoodrich/status/1785...   \n",
       "4006  https://blogs.bl.uk/digitisedmanuscripts/2024/...   \n",
       "\n",
       "                          domain  votes          user           posted_at  \\\n",
       "0                 rubybiscuit.fr      1        dom_fr 2024-04-15 10:39:26   \n",
       "1                theregister.com      1       lproven 2024-04-15 10:40:57   \n",
       "2               alinpanaitiu.com      1         fanf2 2024-04-15 10:42:04   \n",
       "3                    percona.com      2        tie-in 2024-04-15 10:56:16   \n",
       "4                    youtube.com      1        latexr 2024-04-15 10:59:33   \n",
       "...                          ...    ...           ...                 ...   \n",
       "4002                 9to5mac.com      4          mgh2 2024-05-02 03:25:34   \n",
       "4003     alexandrehtrb.github.io      1   thunderbong 2024-05-02 03:31:52   \n",
       "4004   federalreservehistory.org      2          neom 2024-05-02 03:32:39   \n",
       "4005  twitter.com/tuckergoodrich      4  barry-cotter 2024-05-02 03:37:50   \n",
       "4006                 blogs.bl.uk      1         pepys 2024-05-02 03:40:18   \n",
       "\n",
       "      comments                                       source_title  \\\n",
       "0            0  [HORS SÉRIE #6] Tradition ou Transformation ? ...   \n",
       "1            0    Ubuntu 24.04 'Noble Numbat' belatedly hits beta   \n",
       "2            0  Weird monitor bugs people sent me in the last ...   \n",
       "3            0  SQL Optimizations in PostgreSQL: IN vs EXISTS ...   \n",
       "4            0    The Worst Product I've Ever Reviewed... For Now   \n",
       "...        ...                                                ...   \n",
       "4002         0  An inside look at General Motors' massive gamb...   \n",
       "4003         0            Pipelines for .NET - AlexandreHTRB blog   \n",
       "4004         0  Volcker's Announcement of Anti-Inflation Measures   \n",
       "4005         3                                                  X   \n",
       "4006         0                                   Just a moment...   \n",
       "\n",
       "                                            source_text  frontpage  \n",
       "0     [HORS SÉRIE #6] Tradition ou Transformation ? ...      False  \n",
       "1     Ubuntu 24.04 'Noble Numbat' belatedly hits bet...      False  \n",
       "2     Weird monitor bugs people sent me in the last ...      False  \n",
       "3     SQL Optimizations in PostgreSQL: IN vs EXISTS ...      False  \n",
       "4     The Worst Product I've Ever Reviewed... For No...      False  \n",
       "...                                                 ...        ...  \n",
       "4002  An inside look at General Motors' massive gamb...       True  \n",
       "4003  Pipelines for .NET - AlexandreHTRB blog\\n\\nPip...      False  \n",
       "4004  Volcker's Announcement of Anti-Inflation Measu...      False  \n",
       "4005  X\\n\\nDon’t miss what’s happening\\n\\nPeople on ...       True  \n",
       "4006  Just a moment...\\n\\n# blogs.bl.uk\\n\\n## Verify...      False  \n",
       "\n",
       "[4007 rows x 11 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7e82e926-5ffe-4212-93b8-09ab55c8fa28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_directory_empty(directory):\n",
    "    return len(os.listdir(directory)) == 0\n",
    "\n",
    "def write_csv_files(out_dir, df, base_date = None):\n",
    "    weekly_data = df.resample('W-Mon', on='posted_at', origin=base_date).first()\n",
    "    for start_date, end_date in zip(weekly_data.index, weekly_data.index[1:]):\n",
    "        weekly_chunk = df[(df['posted_at'] >= start_date) & (df['posted_at'] < end_date)].reset_index(drop = True)\n",
    "        # Write the weekly chunk to a CSV file\n",
    "        output_file = os.path.join(out_dir, f'weekly_data_{start_date.date()}_{end_date.date() - timedelta(days=1)}.csv')\n",
    "        weekly_chunk.to_csv(output_file, index=False)\n",
    "\n",
    "output_directory = \"C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/Weekly_Data\"\n",
    "files = os.listdir(output_directory)\n",
    "pattern = r'\\d{4}-\\d{2}-\\d{2}'\n",
    "\n",
    "is_directory_empty(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249acbc-7c15-4807-8c00-a459a030df61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_directory_empty(directory):\n",
    "    return len(os.listdir(directory)) == 0\n",
    "\n",
    "def get_last_date(pattern, files)\n",
    "    last_dates = []\n",
    "    for file in files:\n",
    "        matches = re.findall(pattern, file)\n",
    "        last_date_file = matches[-1]\n",
    "        last_dates.append(last_dates)\n",
    "    dates = [datetime.strptime(date, '%Y-%m-%d') for date in dates]\n",
    "    latest_date = max(dates)\n",
    "    return latest_date\n",
    "\n",
    "def merge_data_with_old(df, out_dir, start_date, end_date):\n",
    "    weekly_chunk = df[(df['posted_at'] >= start_date) & (df['posted_at'] < end_date)].reset_index(drop = True)\n",
    "    output_file = os.path.join(out_dir, f'weekly_data_{start_date.date()}_{end_date.date() - timedelta(days=1)}.csv')\n",
    "    weekly_old = pd.read_csv(output_file)\n",
    "    weekly_new = pd.concat([weekly_chunk, weekly_old], axis=0, ignore_index=True)\n",
    "    weekly_new = weekly_new.sort_values(by = 'posted_at', ascending = True).reset_index(drop = True)\n",
    "    weekly_new = weekly_new.drop_duplicates().reset_index(drop = True)\n",
    "    weekly_new.to_csv(output_file, index = False)\n",
    "    \n",
    "def write_csv_files(out_dir, base_date = None, df):\n",
    "    weekly_data = df.resample('W-Mon', on='posted_at', origin=base_date).first()\n",
    "    for start_date, end_date in zip(weekly_data.index, weekly_data.index[1:]):\n",
    "        weekly_chunk = df[(df['posted_at'] >= start_date) & (df['posted_at'] < end_date)].reset_index(drop = True)\n",
    "        # Write the weekly chunk to a CSV file\n",
    "        output_file = os.path.join(out_dir, f'weekly_data_{start_date.date()}_{end_date.date() - timedelta(days=1)}.csv')\n",
    "        weekly_chunk.to_csv(output_file, index=False)\n",
    "\n",
    "output_directory = \"C:/Users/jorge/OneDrive/Escritorio/spark/notebooks/Weekly_Data\"\n",
    "files = os.listdir(output_directory)\n",
    "pattern = r'\\d{4}-\\d{2}-\\d{2}'\n",
    "\n",
    "if is_directory_empty(output_directory):\n",
    "    write_csv_files(out_dir = output_directory, df = final_df)\n",
    "else:\n",
    "    latest_date = get_last_date(pattern, files)\n",
    "    if final_df['started_at'][0] <= latest_date:\n",
    "        oldfile_date = latest_date - timedelta(days=6)\n",
    "        weekly_data = final_df.resample('W-Mon', on='posted_at', origin=oldfile_date).first()\n",
    "        first_start_date = weekly_data.index[0]\n",
    "        first_end_date = weekly_data.index[1]\n",
    "        merge_data_with_old(final_df, output_directory, first_start_date, first_end_date)\n",
    "        \n",
    "        rest_df = final_df[final_df['posted_at'] >= first_end_date]\n",
    "        write_csv_files(output_directory, latest_date + timedelta(days = 1), rest_df)\n",
    "\n",
    "    else:\n",
    "        write_csv_files(output_directory, latest_date + timedelta(days = 1), final_df)\n",
    "    \n",
    "#If directory is not empty, then check if first date is in last week's dataframe (first date < last date in name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
