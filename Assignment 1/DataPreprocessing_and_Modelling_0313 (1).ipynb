{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9ee7beb-33b5-4342-b313-f1ea1a628a11",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3fc918-15d8-4b93-9212-0d8bf61843b5",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d77eea7d-df06-463d-bea6-917a07690551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f605fbfd-1132-4c29-8202-cd60fe810191",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns = \"target\")\n",
    "y = train[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d05c9fac-609a-4ce9-bc68-daf005aaa96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6394db26-7a94-44c7-ab86-97c922e565fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['target'] = y_train\n",
    "X_val['target'] = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5ea743b-b1fe-4306-8ac3-fb0a97c39636",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_train.copy()\n",
    "val = X_val.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be934118-72ca-4d12-8c30-c12c28cb154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()\n",
    "val = val.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19689f40-ad33-491e-88e0-c11e64c69d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep average cost min\n",
    "averagecostmin = val['average cost min']\n",
    "idtest = test[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3189082c-cd5a-406a-966b-4fb54b519bf6",
   "metadata": {},
   "source": [
    "## Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1fe84ec-588a-4af9-887a-40012d7cd10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>L_O_S</th>\n",
       "      <th>Dropped_Calls</th>\n",
       "      <th>Peak_calls_Sum</th>\n",
       "      <th>Peak_mins_Sum</th>\n",
       "      <th>OffPeak_calls_Sum</th>\n",
       "      <th>OffPeak_mins_Sum</th>\n",
       "      <th>Weekend_calls_Sum</th>\n",
       "      <th>Weekend_mins_Sum</th>\n",
       "      <th>International_mins_Sum</th>\n",
       "      <th>...</th>\n",
       "      <th>call_cost_per_min</th>\n",
       "      <th>actual call cost</th>\n",
       "      <th>Total_call_cost</th>\n",
       "      <th>Total_Cost</th>\n",
       "      <th>average cost min</th>\n",
       "      <th>Peak ratio</th>\n",
       "      <th>OffPeak ratio</th>\n",
       "      <th>Weekend ratio</th>\n",
       "      <th>Nat-InterNat Ratio</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4032.000000</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>4032.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31.418403</td>\n",
       "      <td>33.692675</td>\n",
       "      <td>2.673115</td>\n",
       "      <td>239.123016</td>\n",
       "      <td>709.319559</td>\n",
       "      <td>104.113839</td>\n",
       "      <td>312.170469</td>\n",
       "      <td>16.334821</td>\n",
       "      <td>50.117233</td>\n",
       "      <td>169.677704</td>\n",
       "      <td>...</td>\n",
       "      <td>10.081397</td>\n",
       "      <td>19.148192</td>\n",
       "      <td>73.555944</td>\n",
       "      <td>186.897819</td>\n",
       "      <td>0.168059</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.328068</td>\n",
       "      <td>0.061763</td>\n",
       "      <td>0.162448</td>\n",
       "      <td>0.146329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.778218</td>\n",
       "      <td>14.006476</td>\n",
       "      <td>3.419745</td>\n",
       "      <td>239.289112</td>\n",
       "      <td>503.745589</td>\n",
       "      <td>97.255574</td>\n",
       "      <td>199.059794</td>\n",
       "      <td>16.296709</td>\n",
       "      <td>36.080006</td>\n",
       "      <td>141.764351</td>\n",
       "      <td>...</td>\n",
       "      <td>2.108023</td>\n",
       "      <td>27.992736</td>\n",
       "      <td>59.989152</td>\n",
       "      <td>82.037001</td>\n",
       "      <td>0.077313</td>\n",
       "      <td>0.223896</td>\n",
       "      <td>0.209820</td>\n",
       "      <td>0.063645</td>\n",
       "      <td>0.105589</td>\n",
       "      <td>0.353480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>9.633333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034634</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010390</td>\n",
       "      <td>60.000842</td>\n",
       "      <td>0.048998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>21.291667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>307.800001</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>64.538731</td>\n",
       "      <td>...</td>\n",
       "      <td>8.573250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.168235</td>\n",
       "      <td>123.926851</td>\n",
       "      <td>0.134406</td>\n",
       "      <td>0.466570</td>\n",
       "      <td>0.165197</td>\n",
       "      <td>0.020977</td>\n",
       "      <td>0.079269</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>33.650000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>291.150000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>44.399999</td>\n",
       "      <td>132.301181</td>\n",
       "      <td>...</td>\n",
       "      <td>9.518597</td>\n",
       "      <td>7.547389</td>\n",
       "      <td>57.875946</td>\n",
       "      <td>173.404650</td>\n",
       "      <td>0.154501</td>\n",
       "      <td>0.654919</td>\n",
       "      <td>0.287928</td>\n",
       "      <td>0.043940</td>\n",
       "      <td>0.157865</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>45.933333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>343.000000</td>\n",
       "      <td>1014.900000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>446.475000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>236.883563</td>\n",
       "      <td>...</td>\n",
       "      <td>11.696253</td>\n",
       "      <td>28.328732</td>\n",
       "      <td>99.290441</td>\n",
       "      <td>232.132750</td>\n",
       "      <td>0.179244</td>\n",
       "      <td>0.782404</td>\n",
       "      <td>0.458625</td>\n",
       "      <td>0.081047</td>\n",
       "      <td>0.244300</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>58.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1626.000000</td>\n",
       "      <td>2901.600001</td>\n",
       "      <td>560.000000</td>\n",
       "      <td>1091.099999</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>935.947864</td>\n",
       "      <td>...</td>\n",
       "      <td>21.734694</td>\n",
       "      <td>184.892166</td>\n",
       "      <td>437.063835</td>\n",
       "      <td>587.063835</td>\n",
       "      <td>1.357564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.731884</td>\n",
       "      <td>2.601223</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age        L_O_S  Dropped_Calls  Peak_calls_Sum  Peak_mins_Sum  \\\n",
       "count  4032.000000  4032.000000    4032.000000     4032.000000    4032.000000   \n",
       "mean     31.418403    33.692675       2.673115      239.123016     709.319559   \n",
       "std      12.778218    14.006476       3.419745      239.289112     503.745589   \n",
       "min      12.000000     9.633333       0.000000        0.000000       0.000000   \n",
       "25%      22.000000    21.291667       0.000000       59.000000     307.800001   \n",
       "50%      29.000000    33.650000       1.000000      161.000000     615.000000   \n",
       "75%      39.000000    45.933333       2.000000      343.000000    1014.900000   \n",
       "max      80.000000    58.200000      15.000000     1626.000000    2901.600001   \n",
       "\n",
       "       OffPeak_calls_Sum  OffPeak_mins_Sum  Weekend_calls_Sum  \\\n",
       "count        4032.000000       4032.000000        4032.000000   \n",
       "mean          104.113839        312.170469          16.334821   \n",
       "std            97.255574        199.059794          16.296709   \n",
       "min             0.000000          0.000000           0.000000   \n",
       "25%            28.000000        150.000000           4.000000   \n",
       "50%            73.000000        291.150000          11.000000   \n",
       "75%           156.000000        446.475000          24.000000   \n",
       "max           560.000000       1091.099999         106.000000   \n",
       "\n",
       "       Weekend_mins_Sum  International_mins_Sum  ...  call_cost_per_min  \\\n",
       "count       4032.000000             4032.000000  ...        4032.000000   \n",
       "mean          50.117233              169.677704  ...          10.081397   \n",
       "std           36.080006              141.764351  ...           2.108023   \n",
       "min            0.000000                0.034634  ...           2.000000   \n",
       "25%           22.800000               64.538731  ...           8.573250   \n",
       "50%           44.399999              132.301181  ...           9.518597   \n",
       "75%           72.000000              236.883563  ...          11.696253   \n",
       "max          205.000000              935.947864  ...          21.734694   \n",
       "\n",
       "       actual call cost  Total_call_cost   Total_Cost  average cost min  \\\n",
       "count       4032.000000      4032.000000  4032.000000       4032.000000   \n",
       "mean          19.148192        73.555944   186.897819          0.168059   \n",
       "std           27.992736        59.989152    82.037001          0.077313   \n",
       "min            0.000000         0.010390    60.000842          0.048998   \n",
       "25%            0.000000        32.168235   123.926851          0.134406   \n",
       "50%            7.547389        57.875946   173.404650          0.154501   \n",
       "75%           28.328732        99.290441   232.132750          0.179244   \n",
       "max          184.892166       437.063835   587.063835          1.357564   \n",
       "\n",
       "        Peak ratio  OffPeak ratio  Weekend ratio  Nat-InterNat Ratio  \\\n",
       "count  4032.000000    4032.000000    4032.000000         4032.000000   \n",
       "mean      0.610169       0.328068       0.061763            0.162448   \n",
       "std       0.223896       0.209820       0.063645            0.105589   \n",
       "min       0.000000       0.000000       0.000000            0.000030   \n",
       "25%       0.466570       0.165197       0.020977            0.079269   \n",
       "50%       0.654919       0.287928       0.043940            0.157865   \n",
       "75%       0.782404       0.458625       0.081047            0.244300   \n",
       "max       1.000000       1.000000       0.731884            2.601223   \n",
       "\n",
       "            target  \n",
       "count  4032.000000  \n",
       "mean      0.146329  \n",
       "std       0.353480  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df64bf10-853c-4384-b3b1-b84d352b5d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Connect_Date</th>\n",
       "      <th>tariff</th>\n",
       "      <th>Handset</th>\n",
       "      <th>Usage_Band</th>\n",
       "      <th>Tariff_OK</th>\n",
       "      <th>high Dropped calls</th>\n",
       "      <th>No Usage</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4032</td>\n",
       "      <td>4032</td>\n",
       "      <td>4032</td>\n",
       "      <td>4032</td>\n",
       "      <td>4032</td>\n",
       "      <td>4032</td>\n",
       "      <td>4032</td>\n",
       "      <td>4032</td>\n",
       "      <td>4032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>1310</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>F</td>\n",
       "      <td>11/07/99</td>\n",
       "      <td>CAT 200</td>\n",
       "      <td>S50</td>\n",
       "      <td>Med</td>\n",
       "      <td>OK</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>K277140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2040</td>\n",
       "      <td>11</td>\n",
       "      <td>1802</td>\n",
       "      <td>944</td>\n",
       "      <td>2232</td>\n",
       "      <td>4003</td>\n",
       "      <td>3930</td>\n",
       "      <td>4032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gender Connect_Date   tariff Handset Usage_Band Tariff_OK  \\\n",
       "count    4032         4032     4032    4032       4032      4032   \n",
       "unique      2         1310        5      11          5         4   \n",
       "top         F     11/07/99  CAT 200     S50        Med        OK   \n",
       "freq     2040           11     1802     944       2232      4003   \n",
       "\n",
       "       high Dropped calls No Usage       id  \n",
       "count                4032     4032     4032  \n",
       "unique                  2        1     4032  \n",
       "top                     F        F  K277140  \n",
       "freq                 3930     4032        1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe(include = 'object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4b5024-442e-42a9-bd92-8b6b8d5e1b29",
   "metadata": {},
   "source": [
    "## Prepocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2f9913-878f-44b0-988e-7aafd7c49780",
   "metadata": {},
   "source": [
    "### Drop ID, drop Connect_Date (too many unique values, do not provide information on response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7ccaee8-e9ac-4d59-8282-b3966d70dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns = [\"id\", \"Connect_Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6d33d07-29f2-4bcc-ba47-07a01ad0f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = val.drop(columns = [\"id\", \"Connect_Date\"])\n",
    "test = test.drop(columns = [\"id\", \"Connect_Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a285161-ac3e-40f4-959a-96a312d13c3a",
   "metadata": {},
   "source": [
    "### Dropping numerical variables that are useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24e15144-2132-468d-aebc-12e7fad13fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = train[train.select_dtypes(include=['number']).columns.tolist()].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a3a7a66-9692-4949-ae66-163a5618bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrtarget = correlation_matrix['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c6148e9-6c5e-4a92-af9e-fc9266139bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make plot for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bda31f47-827a-4d24-8dc5-a53e36457e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_correlation_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.8:\n",
    "            high_correlation_pairs.append((correlation_matrix.columns[i], correlation_matrix.columns[j]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9648355-1bf2-49eb-ac84-2be575dd6f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Peak_calls_Sum', 'National_calls'),\n",
       " ('Peak_mins_Sum', 'National mins'),\n",
       " ('Peak_mins_Sum', 'All_calls_mins'),\n",
       " ('Peak_mins_Sum', 'Total_Cost'),\n",
       " ('International_mins_Sum', 'Total_call_cost'),\n",
       " ('International_mins_Sum', 'Total_Cost'),\n",
       " ('Nat_call_cost_Sum', 'Mins_charge'),\n",
       " ('Nat_call_cost_Sum', 'actual call cost'),\n",
       " ('National mins', 'All_calls_mins'),\n",
       " ('National mins', 'Total_Cost'),\n",
       " ('All_calls_mins', 'Total_call_cost'),\n",
       " ('All_calls_mins', 'Total_Cost'),\n",
       " ('Mins_charge', 'actual call cost'),\n",
       " ('Total_call_cost', 'Total_Cost'),\n",
       " ('Peak ratio', 'OffPeak ratio')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_correlation_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae18ac40-73c0-44b7-8c37-bdbf890f18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def build_adjacency_list(pairs):\n",
    "    adjacency_list = defaultdict(list)\n",
    "    for u, v in pairs:\n",
    "        adjacency_list[u].append(v)\n",
    "        adjacency_list[v].append(u)\n",
    "    return adjacency_list\n",
    "\n",
    "# Function to perform depth-first search (DFS) traversal to find connected components\n",
    "def dfs(node, adjacency_list, visited, component):\n",
    "    visited.add(node)\n",
    "    component.append(node)\n",
    "    for neighbor in adjacency_list[node]:\n",
    "        if neighbor not in visited:\n",
    "            dfs(neighbor, adjacency_list, visited, component)\n",
    "\n",
    "# Function to find connected components in the graph\n",
    "def find_connected_components(pairs):\n",
    "    adjacency_list = build_adjacency_list(pairs)\n",
    "    visited = set()\n",
    "    connected_components = []\n",
    "    for node in adjacency_list:\n",
    "        if node not in visited:\n",
    "            component = []\n",
    "            dfs(node, adjacency_list, visited, component)\n",
    "            connected_components.append(component)\n",
    "    return connected_components\n",
    "\n",
    "# Find connected groups\n",
    "connected_groups = find_connected_components(high_correlation_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e99d9c8f-7d0e-469e-ae02-2a6597614ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variables_to_drop(group, corrtarget):\n",
    "    max_cor = 0\n",
    "    var_max = ''\n",
    "    for var in group:\n",
    "        if abs(corrtarget[var]) > max_cor:\n",
    "            var_max = var\n",
    "    group.remove(var_max)\n",
    "\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd8e458f-0ac7-46d5-a383-2f992fce22c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_drop = [get_variables_to_drop(group, corrtarget) for group in connected_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d56c236-07ec-4594-999a-fd54e5ce1f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_vars = [item for sublist in variables_to_drop for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6f371d3-71ad-4ac5-8f0c-4e884e39a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns = drop_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "53687937-c8eb-44eb-9545-eed5d5a00011",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = val.drop(columns = drop_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "47e0a8b5-6960-40c0-aa3e-0452f2cf7f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns = drop_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb32571-a400-436b-afde-0611cb7d73bb",
   "metadata": {},
   "source": [
    "### Deleting categorical variables that are useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e271fad2-0b6b-4c11-80df-e7b7ca38bb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target  Gender\n",
      "0       F         1760\n",
      "        M         1682\n",
      "1       M          310\n",
      "        F          280\n",
      "Name: Gender, dtype: int64\n",
      "target  tariff  \n",
      "0       CAT 200     1533\n",
      "        CAT 100      736\n",
      "        Play 100     502\n",
      "        Play 300     471\n",
      "        CAT 50       200\n",
      "1       CAT 200      269\n",
      "        Play 100     126\n",
      "        CAT 100      110\n",
      "        Play 300      47\n",
      "        CAT 50        38\n",
      "Name: tariff, dtype: int64\n",
      "target  Handset\n",
      "0       S50        825\n",
      "        BS110      598\n",
      "        S80        574\n",
      "        WC95       526\n",
      "        ASAD170    514\n",
      "        BS210      220\n",
      "        CAS60       90\n",
      "        ASAD90      42\n",
      "        CAS30       37\n",
      "        SOP20       10\n",
      "        SOP10        6\n",
      "1       ASAD90     174\n",
      "        S50        119\n",
      "        CAS30      106\n",
      "        BS110       95\n",
      "        SOP10       28\n",
      "        SOP20       24\n",
      "        S80         20\n",
      "        ASAD170     10\n",
      "        BS210        8\n",
      "        WC95         6\n",
      "Name: Handset, dtype: int64\n",
      "target  Usage_Band\n",
      "0       Med           1973\n",
      "        MedHigh        866\n",
      "        MedLow         310\n",
      "        High           246\n",
      "        Low             47\n",
      "1       Med            259\n",
      "        MedHigh        148\n",
      "        MedLow         120\n",
      "        High            42\n",
      "        Low             21\n",
      "Name: Usage_Band, dtype: int64\n",
      "target  Tariff_OK    \n",
      "0       OK               3435\n",
      "        High CAT 100        5\n",
      "        High CAT 50         1\n",
      "        High Play 100       1\n",
      "1       OK                568\n",
      "        High CAT 100       16\n",
      "        High CAT 50         4\n",
      "        High Play 100       2\n",
      "Name: Tariff_OK, dtype: int64\n",
      "target  high Dropped calls\n",
      "0       F                     3425\n",
      "        T                       17\n",
      "1       F                      505\n",
      "        T                       85\n",
      "Name: high Dropped calls, dtype: int64\n",
      "target  No Usage\n",
      "0       F           3442\n",
      "1       F            590\n",
      "Name: No Usage, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for variable in list(train.describe(include = 'object').columns):\n",
    "    print(train.groupby('target')[variable].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fad58b1b-45b6-46b9-a756-461b30c3013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make plots for this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cc6288-b781-41c1-9bc6-d102c26a95a4",
   "metadata": {},
   "source": [
    "No Usage, UsageBand, Tariff seem totally useless, they are dropped for now\n",
    "Most useful inferences: High Dropped Calls seems a good indicator for whether someone will churn or not, ratio of Trues for churners is much higher. Tariff_Ok's High Cat 100 for churners is much higher than for non churners, would be good to add numerical encoding. Same for handset, numerical encoding would be nice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9fba3d73-6cd5-4153-9a45-d87f63bae2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns = [\"No Usage\", \"Usage_Band\", \"tariff\"])\n",
    "test = test.drop(columns = [\"No Usage\", \"Usage_Band\", \"tariff\"])\n",
    "val = val.drop(columns = [\"No Usage\", \"Usage_Band\", \"tariff\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f42c9ca-9c98-40f6-abf5-fabb5582202d",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f8f52ad-dc03-44f9-b571-eb22475b1530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                 0\n",
       "Age                    0\n",
       "L_O_S                  0\n",
       "Dropped_Calls          0\n",
       "Handset                0\n",
       "OffPeak_calls_Sum      0\n",
       "OffPeak_mins_Sum       0\n",
       "Weekend_calls_Sum      0\n",
       "Weekend_mins_Sum       0\n",
       "AvePeak                0\n",
       "AveOffPeak             0\n",
       "AveWeekend             0\n",
       "National_calls         0\n",
       "AveNational            0\n",
       "Dropped_calls_ratio    0\n",
       "call_cost_per_min      0\n",
       "actual call cost       0\n",
       "Total_Cost             0\n",
       "Tariff_OK              0\n",
       "average cost min       0\n",
       "OffPeak ratio          0\n",
       "Weekend ratio          0\n",
       "Nat-InterNat Ratio     0\n",
       "high Dropped calls     0\n",
       "target                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631b7bdf-f8ac-4192-b9ce-9880a8e8d187",
   "metadata": {},
   "source": [
    "Almost no missing values, these could be imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "94e858d5-7f9c-4737-9651-b354db8a4998",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_missing_values = train[train.isnull().any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b8faa349-409d-41c6-875d-edc7a6674e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call_cost_per_min</th>\n",
       "      <th>Dropped_calls_ratio</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [call_cost_per_min, Dropped_calls_ratio, target]\n",
       "Index: []"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_with_missing_values[[\"call_cost_per_min\", \"Dropped_calls_ratio\", \"target\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6a74f4-ceb7-4c8c-9f7c-91b369da8b98",
   "metadata": {},
   "source": [
    "Missing values are all in the same 4 rows. Since they're only 4 observations out of 5000, they're eliminated from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35468cfa-7ceb-4bcc-b5d6-b8c54d7507e3",
   "metadata": {},
   "source": [
    "Outliers are not dealt with (they are useful in our detection, the higher the costs the bigger the probability of churning?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ab7516-4fa6-4688-b445-94f42594758a",
   "metadata": {},
   "source": [
    "### Transformation of Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b73c81b-ddc7-4280-84c5-47793d6c4031",
   "metadata": {},
   "source": [
    "#### Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "254554dc-53d7-4f53-807b-ffe18e153762",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "81c7c863-7b74-4977-9371-296cccdcf51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>L_O_S</th>\n",
       "      <th>Dropped_Calls</th>\n",
       "      <th>Handset</th>\n",
       "      <th>OffPeak_calls_Sum</th>\n",
       "      <th>OffPeak_mins_Sum</th>\n",
       "      <th>Weekend_calls_Sum</th>\n",
       "      <th>Weekend_mins_Sum</th>\n",
       "      <th>AvePeak</th>\n",
       "      <th>...</th>\n",
       "      <th>call_cost_per_min</th>\n",
       "      <th>actual call cost</th>\n",
       "      <th>Total_Cost</th>\n",
       "      <th>Tariff_OK</th>\n",
       "      <th>average cost min</th>\n",
       "      <th>OffPeak ratio</th>\n",
       "      <th>Weekend ratio</th>\n",
       "      <th>Nat-InterNat Ratio</th>\n",
       "      <th>high Dropped calls</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>20.0</td>\n",
       "      <td>55.582251</td>\n",
       "      <td>3.0</td>\n",
       "      <td>WC95</td>\n",
       "      <td>110.0</td>\n",
       "      <td>189.982227</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.017969</td>\n",
       "      <td>9.598648</td>\n",
       "      <td>...</td>\n",
       "      <td>8.933287</td>\n",
       "      <td>9.409262</td>\n",
       "      <td>167.242853</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.116924</td>\n",
       "      <td>0.173365</td>\n",
       "      <td>0.009823</td>\n",
       "      <td>0.020349</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>54.0</td>\n",
       "      <td>32.067010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BS110</td>\n",
       "      <td>93.0</td>\n",
       "      <td>551.817423</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.593417</td>\n",
       "      <td>33.547208</td>\n",
       "      <td>...</td>\n",
       "      <td>11.931697</td>\n",
       "      <td>2.739423</td>\n",
       "      <td>136.404621</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.120457</td>\n",
       "      <td>0.532898</td>\n",
       "      <td>0.022391</td>\n",
       "      <td>0.124480</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>28.0</td>\n",
       "      <td>26.621954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ASAD170</td>\n",
       "      <td>90.0</td>\n",
       "      <td>152.731006</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.907633</td>\n",
       "      <td>2.945673</td>\n",
       "      <td>...</td>\n",
       "      <td>9.560903</td>\n",
       "      <td>95.406158</td>\n",
       "      <td>397.739114</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.149435</td>\n",
       "      <td>0.034434</td>\n",
       "      <td>0.006660</td>\n",
       "      <td>0.225763</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.652735</td>\n",
       "      <td>5.0</td>\n",
       "      <td>WC95</td>\n",
       "      <td>126.0</td>\n",
       "      <td>358.760706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.024655</td>\n",
       "      <td>11.984087</td>\n",
       "      <td>...</td>\n",
       "      <td>8.398145</td>\n",
       "      <td>14.464628</td>\n",
       "      <td>196.789012</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.137372</td>\n",
       "      <td>0.263256</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>0.108872</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>34.0</td>\n",
       "      <td>25.479355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WC95</td>\n",
       "      <td>73.0</td>\n",
       "      <td>141.180280</td>\n",
       "      <td>11.0</td>\n",
       "      <td>47.034972</td>\n",
       "      <td>8.875573</td>\n",
       "      <td>...</td>\n",
       "      <td>12.766109</td>\n",
       "      <td>34.757126</td>\n",
       "      <td>160.450386</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.180704</td>\n",
       "      <td>0.166995</td>\n",
       "      <td>0.056390</td>\n",
       "      <td>0.090896</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>F</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.097166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BS110</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.952890</td>\n",
       "      <td>45.0</td>\n",
       "      <td>105.774031</td>\n",
       "      <td>0.802079</td>\n",
       "      <td>...</td>\n",
       "      <td>9.588439</td>\n",
       "      <td>35.396282</td>\n",
       "      <td>208.523608</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.122342</td>\n",
       "      <td>0.012611</td>\n",
       "      <td>0.070297</td>\n",
       "      <td>0.035339</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>M</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.594431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BS110</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>73.643988</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.751955</td>\n",
       "      <td>-2.663694</td>\n",
       "      <td>...</td>\n",
       "      <td>13.794174</td>\n",
       "      <td>30.518649</td>\n",
       "      <td>147.689743</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.163502</td>\n",
       "      <td>0.052157</td>\n",
       "      <td>0.041489</td>\n",
       "      <td>0.079988</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>F</td>\n",
       "      <td>34.0</td>\n",
       "      <td>55.339646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S50</td>\n",
       "      <td>21.0</td>\n",
       "      <td>278.414345</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.029118</td>\n",
       "      <td>8.078580</td>\n",
       "      <td>...</td>\n",
       "      <td>9.031387</td>\n",
       "      <td>96.373049</td>\n",
       "      <td>302.935896</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.127485</td>\n",
       "      <td>0.106429</td>\n",
       "      <td>0.011459</td>\n",
       "      <td>0.098248</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>M</td>\n",
       "      <td>21.0</td>\n",
       "      <td>42.830741</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BS110</td>\n",
       "      <td>76.0</td>\n",
       "      <td>196.742943</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>18.472483</td>\n",
       "      <td>-3.877556</td>\n",
       "      <td>...</td>\n",
       "      <td>11.898371</td>\n",
       "      <td>-0.223523</td>\n",
       "      <td>159.088917</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.205830</td>\n",
       "      <td>0.358159</td>\n",
       "      <td>0.017720</td>\n",
       "      <td>0.256554</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>F</td>\n",
       "      <td>15.0</td>\n",
       "      <td>48.586523</td>\n",
       "      <td>2.0</td>\n",
       "      <td>WC95</td>\n",
       "      <td>216.0</td>\n",
       "      <td>570.140734</td>\n",
       "      <td>29.0</td>\n",
       "      <td>64.926550</td>\n",
       "      <td>47.878778</td>\n",
       "      <td>...</td>\n",
       "      <td>7.678638</td>\n",
       "      <td>-0.606908</td>\n",
       "      <td>79.363539</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.110151</td>\n",
       "      <td>0.718294</td>\n",
       "      <td>0.069951</td>\n",
       "      <td>0.011028</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender   Age      L_O_S  Dropped_Calls  Handset  OffPeak_calls_Sum  \\\n",
       "0         F  20.0  55.582251            3.0     WC95              110.0   \n",
       "1         F  54.0  32.067010            0.0    BS110               93.0   \n",
       "2         F  28.0  26.621954            0.0  ASAD170               90.0   \n",
       "3         F  26.0  27.652735            5.0     WC95              126.0   \n",
       "4         F  34.0  25.479355            0.0     WC95               73.0   \n",
       "...     ...   ...        ...            ...      ...                ...   \n",
       "1677      F  32.0  40.097166            0.0    BS110                8.0   \n",
       "1678      M  19.0  22.594431            0.0    BS110               -1.0   \n",
       "1679      F  34.0  55.339646            0.0      S50               21.0   \n",
       "1680      M  21.0  42.830741            2.0    BS110               76.0   \n",
       "1681      F  15.0  48.586523            2.0     WC95              216.0   \n",
       "\n",
       "      OffPeak_mins_Sum  Weekend_calls_Sum  Weekend_mins_Sum    AvePeak  ...  \\\n",
       "0           189.982227                8.0          5.017969   9.598648  ...   \n",
       "1           551.817423                8.0         17.593417  33.547208  ...   \n",
       "2           152.731006               10.0         23.907633   2.945673  ...   \n",
       "3           358.760706                0.0          3.024655  11.984087  ...   \n",
       "4           141.180280               11.0         47.034972   8.875573  ...   \n",
       "...                ...                ...               ...        ...  ...   \n",
       "1677         42.952890               45.0        105.774031   0.802079  ...   \n",
       "1678         73.643988                2.0         28.751955  -2.663694  ...   \n",
       "1679        278.414345                2.0         34.029118   8.078580  ...   \n",
       "1680        196.742943               -1.0         18.472483  -3.877556  ...   \n",
       "1681        570.140734               29.0         64.926550  47.878778  ...   \n",
       "\n",
       "      call_cost_per_min  actual call cost  Total_Cost  Tariff_OK  \\\n",
       "0              8.933287          9.409262  167.242853         OK   \n",
       "1             11.931697          2.739423  136.404621         OK   \n",
       "2              9.560903         95.406158  397.739114         OK   \n",
       "3              8.398145         14.464628  196.789012         OK   \n",
       "4             12.766109         34.757126  160.450386         OK   \n",
       "...                 ...               ...         ...        ...   \n",
       "1677           9.588439         35.396282  208.523608         OK   \n",
       "1678          13.794174         30.518649  147.689743         OK   \n",
       "1679           9.031387         96.373049  302.935896         OK   \n",
       "1680          11.898371         -0.223523  159.088917         OK   \n",
       "1681           7.678638         -0.606908   79.363539         OK   \n",
       "\n",
       "      average cost min  OffPeak ratio  Weekend ratio  Nat-InterNat Ratio  \\\n",
       "0             0.116924       0.173365       0.009823            0.020349   \n",
       "1             0.120457       0.532898       0.022391            0.124480   \n",
       "2             0.149435       0.034434       0.006660            0.225763   \n",
       "3             0.137372       0.263256       0.005870            0.108872   \n",
       "4             0.180704       0.166995       0.056390            0.090896   \n",
       "...                ...            ...            ...                 ...   \n",
       "1677          0.122342       0.012611       0.070297            0.035339   \n",
       "1678          0.163502       0.052157       0.041489            0.079988   \n",
       "1679          0.127485       0.106429       0.011459            0.098248   \n",
       "1680          0.205830       0.358159       0.017720            0.256554   \n",
       "1681          0.110151       0.718294       0.069951            0.011028   \n",
       "\n",
       "     high Dropped calls  target  \n",
       "0                     F       0  \n",
       "1                     F       0  \n",
       "2                     F       0  \n",
       "3                     F       0  \n",
       "4                     F       0  \n",
       "...                 ...     ...  \n",
       "1677                  F       0  \n",
       "1678                  F       0  \n",
       "1679                  F       0  \n",
       "1680                  F       0  \n",
       "1681                  F       0  \n",
       "\n",
       "[1682 rows x 25 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "363abba2-45cf-4356-9f95-30325c6f161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# List of numerical variable names\n",
    "numerical_features = train.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "# List of categorical variable names (replace with actual categorical variable names)\n",
    "categorical_features = train.select_dtypes(exclude=['number']).columns.tolist()\n",
    "\n",
    "# Define the transformers\n",
    "transformers = [\n",
    "    ('num', MinMaxScaler(), numerical_features)\n",
    "]\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(transformers, remainder='passthrough')\n",
    "\n",
    "# Apply the column transformer to the data\n",
    "transformed_train = preprocessor.fit_transform(train)\n",
    "transformed_val = preprocessor.transform(val)\n",
    "transformed_test = preprocessor.transform(test)\n",
    "\n",
    "\n",
    "# Convert the transformed data back to DataFrame\n",
    "transformed_train = pd.DataFrame(transformed_train, columns=numerical_features + categorical_features)\n",
    "transformed_test = pd.DataFrame(transformed_test, columns=numerical_features + categorical_features)\n",
    "transformed_val = pd.DataFrame(transformed_val, columns=numerical_features + categorical_features)\n",
    "\n",
    "\n",
    "\n",
    "# Only the numerical variables will be scaled to the range [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6589dba-6067-4f1d-8333-5f28503ef36b",
   "metadata": {},
   "source": [
    "MinMaxScaling (0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7350b4c-91ef-40fb-8d10-776545fd782c",
   "metadata": {},
   "source": [
    "MinMaxScaling (-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbf6440-df4b-42ae-857b-dda52767f81c",
   "metadata": {},
   "source": [
    "Normalization + MinMaxScaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d523173-e3be-4e29-be1c-a5695fb3d6f5",
   "metadata": {},
   "source": [
    "#### Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ad6260-2d67-4673-b58c-1571fd3d3017",
   "metadata": {},
   "source": [
    "One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "18ff7fc3-b720-4fb0-8d77-7bb0f5df4fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target  Gender\n",
      "0       F         1760\n",
      "        M         1682\n",
      "1       M          310\n",
      "        F          280\n",
      "Name: Gender, dtype: int64\n",
      "target  Handset\n",
      "0       S50        825\n",
      "        BS110      598\n",
      "        S80        574\n",
      "        WC95       526\n",
      "        ASAD170    514\n",
      "        BS210      220\n",
      "        CAS60       90\n",
      "        ASAD90      42\n",
      "        CAS30       37\n",
      "        SOP20       10\n",
      "        SOP10        6\n",
      "1       ASAD90     174\n",
      "        S50        119\n",
      "        CAS30      106\n",
      "        BS110       95\n",
      "        SOP10       28\n",
      "        SOP20       24\n",
      "        S80         20\n",
      "        ASAD170     10\n",
      "        BS210        8\n",
      "        WC95         6\n",
      "Name: Handset, dtype: int64\n",
      "target  Tariff_OK    \n",
      "0       OK               3435\n",
      "        High CAT 100        5\n",
      "        High CAT 50         1\n",
      "        High Play 100       1\n",
      "1       OK                568\n",
      "        High CAT 100       16\n",
      "        High CAT 50         4\n",
      "        High Play 100       2\n",
      "Name: Tariff_OK, dtype: int64\n",
      "target  high Dropped calls\n",
      "0       F                     3425\n",
      "        T                       17\n",
      "1       F                      505\n",
      "        T                       85\n",
      "Name: high Dropped calls, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for variable in list(train.describe(include = 'object').columns):\n",
    "    print(train.groupby('target')[variable].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "76db170b-67e8-468d-9fee-36d912239c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode binary variables using map\n",
    "binary_mapping1 = {'M': 1, 'F': 0}\n",
    "binary_mapping2 = {'T': 1, 'F': 0}\n",
    "\n",
    "transformed_train['high Dropped calls'] = transformed_train['high Dropped calls'].map(binary_mapping2)\n",
    "transformed_train['Gender'] = transformed_train['Gender'].map(binary_mapping1)\n",
    "transformed_test['high Dropped calls'] = transformed_test['high Dropped calls'].map(binary_mapping2)\n",
    "transformed_test['Gender'] = transformed_test['Gender'].map(binary_mapping1)\n",
    "transformed_val['high Dropped calls'] = transformed_val['high Dropped calls'].map(binary_mapping2)\n",
    "transformed_val['Gender'] = transformed_val['Gender'].map(binary_mapping1)\n",
    "\n",
    "\n",
    "# Filter and encode categorical variables\n",
    "# For categorical_1, keep only 'High CAT 100', encode the rest as 'Other'\n",
    "transformed_train['Tariff_OK'] = transformed_train['Tariff_OK'].apply(lambda x: 1 if x == 'High CAT 100' else 0)\n",
    "transformed_test['Tariff_OK'] = transformed_test['Tariff_OK'].apply(lambda x: 1 if x == 'High CAT 100' else 0)\n",
    "transformed_val['Tariff_OK'] = transformed_val['Tariff_OK'].apply(lambda x: 1 if x == 'High CAT 100' else 0)\n",
    "\n",
    "# Encode categorical_2 using one-hot encoding\n",
    "encoded_train = pd.get_dummies(transformed_train, columns=['Handset'], dtype = int)\n",
    "encoded_test = pd.get_dummies(transformed_test, columns=['Handset'], dtype = int)\n",
    "encoded_val = pd.get_dummies(transformed_val, columns=['Handset'], dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7225146a-fccd-4e8f-95dc-4098b9f2e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train['target'] = encoded_train['target'].astype('category')\n",
    "encoded_val['target'] = encoded_val['target'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "766ae81b-f5f7-49f5-bccc-df5c9a35d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = encoded_train.drop(columns = \"target\")\n",
    "y_train = encoded_train[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "75f1795a-9504-421b-83af-5a9a31f13bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = encoded_val.drop(columns = \"target\")\n",
    "y_val = encoded_val[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f24078f-be11-4913-b69c-a8332cb264c1",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8012493-c50b-4014-8a42-3cc71f696d05",
   "metadata": {},
   "source": [
    "## model 1: random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "52e66609-081c-485a-8749-249fd1bb0037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=20, random_state=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=20, random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7e83107b-068a-464f-b26f-1de7fb881093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125214998280013"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "y_pred = clf.predict(X_val)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_val, y_pred)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d0a9b2f9-bb96-4ed9-8c66-f3c15a2759b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Profit_top_k(df_results, k = 20, var = 'average cost min'):\n",
    "    sorted_df = df_results.sort_values(by= \"predict_proba\", ascending = False)\n",
    "    sum = 0\n",
    "    for i in range(0, k):\n",
    "        if df_results['y_true'][i] == df_results['y_pred'][i]:\n",
    "            sum += df_results[var][i]\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7346e08d-8630-4bec-9eba-b4cc43c2c2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9101036269430051,\n",
       " 0.05012875536480687,\n",
       " 0.74,\n",
       " 0.046477583271527054,\n",
       " 0.046617126364158844,\n",
       " 0.1830222195282894,\n",
       " 0.03172997453602716,\n",
       " 0.07077579745750413,\n",
       " 0.07511319338582051,\n",
       " 0.03410450156101714,\n",
       " 0.010633642090700453,\n",
       " 0.5105168539325843,\n",
       " 0.67,\n",
       " 0.03003900293255132,\n",
       " 0.13774032738095238,\n",
       " 0.05646753820690529,\n",
       " 0.0007277893022629834,\n",
       " 0.040982634332446415,\n",
       " 0.021979803378887715,\n",
       " 0.02324310119528037,\n",
       " 0.03177841029528493,\n",
       " 0.2148526485220954,\n",
       " 0.6614368131868131,\n",
       " 0.023527035248858606,\n",
       " 0.011468609484347638,\n",
       " 0.14524881796690306,\n",
       " 0.01180931873462515,\n",
       " 0.050311168526041714,\n",
       " 0.0914685104985657,\n",
       " 3.4129692832764505e-05,\n",
       " 0.73,\n",
       " 0.06192082562671576,\n",
       " 0.05027442269610975,\n",
       " 0.5158541666666666,\n",
       " 0.016314085404504068,\n",
       " 0.08449647154325572,\n",
       " 0.04109302097311879,\n",
       " 0.14129758653363803,\n",
       " 0.025219051301310767,\n",
       " 0.07003412969283276,\n",
       " 0.016855042819756222,\n",
       " 0.021839852831232145,\n",
       " 0.08060240963855421,\n",
       " 0.06413389882818961,\n",
       " 0.023345454545454544,\n",
       " 0.10082625819827423,\n",
       " 0.08271645412987827,\n",
       " 0.04193351082426063,\n",
       " 0.014531463310042625,\n",
       " 0.12231728276919127,\n",
       " 0.84,\n",
       " 0.030348839165230138,\n",
       " 0.006480265699716885,\n",
       " 0.05624944088918449,\n",
       " 0.74,\n",
       " 0.13,\n",
       " 0.021744227994227993,\n",
       " 0.62,\n",
       " 0.1733904530913972,\n",
       " 0.07338298297691842,\n",
       " 0.03298237639263754,\n",
       " 0.0103771723139205,\n",
       " 0.03249887327215958,\n",
       " 0.0011697168515710208,\n",
       " 0.12369047619047618,\n",
       " 0.043079681831248065,\n",
       " 0.24210124959074542,\n",
       " 0.08586252985898954,\n",
       " 0.10556688963210702,\n",
       " 0.024308241824137062,\n",
       " 0.028013217329328793,\n",
       " 0.2524396182154671,\n",
       " 0.019757603005999068,\n",
       " 0.14128871695680206,\n",
       " 0.2506060606060606,\n",
       " 0.011486806528371247,\n",
       " 0.011897887098381396,\n",
       " 0.012278995362904293,\n",
       " 0.3487709914965872,\n",
       " 0.5353333333333334,\n",
       " 0.03285477928707095,\n",
       " 0.11342881951347898,\n",
       " 0.01140376686376842,\n",
       " 0.94,\n",
       " 0.08240708312914023,\n",
       " 0.05014414414414414,\n",
       " 0.87,\n",
       " 0.02154334482442475,\n",
       " 0.09176374628300665,\n",
       " 0.11280439996310303,\n",
       " 0.056543145192309616,\n",
       " 0.7,\n",
       " 0.35,\n",
       " 0.09051544062502966,\n",
       " 0.03788853295589226,\n",
       " 0.03164915542925325,\n",
       " 0.0010617020764079588,\n",
       " 0.18,\n",
       " 0.1406918428276861,\n",
       " 0.015346496298522382,\n",
       " 0.3769064039408867,\n",
       " 0.03359467794953168,\n",
       " 0.07805901855487535,\n",
       " 0.011267092677398829,\n",
       " 0.029293595758981817,\n",
       " 0.00014524080394387562,\n",
       " 0.06398669251064304,\n",
       " 0.03055977706375953,\n",
       " 0.021733251783253492,\n",
       " 0.0950813244489715,\n",
       " 0.1508872335512079,\n",
       " 0.025271059085280236,\n",
       " 0.026307671532943763,\n",
       " 0.01026497350937684,\n",
       " 0.011700564652061088,\n",
       " 0.0620324569221628,\n",
       " 0.7,\n",
       " 0.07319251467710372,\n",
       " 0.0009311829578071986,\n",
       " 0.04019827607257099,\n",
       " 0.025807050885890925,\n",
       " 0.01191930894164823,\n",
       " 0.047030716149120584,\n",
       " 0.785,\n",
       " 0.09228487673701162,\n",
       " 0.050879103964188654,\n",
       " 0.012178554929352927,\n",
       " 0.050479962721342024,\n",
       " 0.04850141008790246,\n",
       " 0.0008379470379470379,\n",
       " 0.050214327094474154,\n",
       " 0.87,\n",
       " 0.03916374924691323,\n",
       " 0.05039155655816951,\n",
       " 0.04259404141315559,\n",
       " 0.44060481663929935,\n",
       " 0.09421567569882637,\n",
       " 0.06119494737692415,\n",
       " 0.050527761882065016,\n",
       " 0.38,\n",
       " 0.11228807922957897,\n",
       " 0.043152452468557125,\n",
       " 0.08022908760278305,\n",
       " 0.014939714038920828,\n",
       " 0.05604611917867242,\n",
       " 0.029299221020658395,\n",
       " 0.0006266941119882297,\n",
       " 0.10170740963855422,\n",
       " 0.02211557745252137,\n",
       " 0.02094833117939829,\n",
       " 0.82,\n",
       " 0.15106770833333333,\n",
       " 0.023652473036419562,\n",
       " 0.021440751686244194,\n",
       " 0.015726190476190477,\n",
       " 0.011803529200848402,\n",
       " 0.13636292835722202,\n",
       " 0.6504822029822028,\n",
       " 0.89,\n",
       " 0.03594817375321805,\n",
       " 0.0023807931606085273,\n",
       " 0.03717367441400366,\n",
       " 0.0429880190254725,\n",
       " 0.06037233286697572,\n",
       " 0.04299646374096734,\n",
       " 0.11336538461538462,\n",
       " 0.002590374404748549,\n",
       " 0.01117247321129431,\n",
       " 0.7908347694341156,\n",
       " 0.2185364491352003,\n",
       " 0.10497313812566203,\n",
       " 0.01031740673776963,\n",
       " 0.0014050779628054543,\n",
       " 0.1082961038961039,\n",
       " 0.14347758822741105,\n",
       " 0.12933461750932393,\n",
       " 0.17201149425287357,\n",
       " 0.014419885418497045,\n",
       " 0.3720355392156863,\n",
       " 0.010986902321632883,\n",
       " 0.031804001469495774,\n",
       " 0.06219383540461841,\n",
       " 0.1004893363865132,\n",
       " 0.020217391304347826,\n",
       " 0.011220379423314513,\n",
       " 0.07902475212576886,\n",
       " 0.36,\n",
       " 0.14484724003055321,\n",
       " 0.88,\n",
       " 0.1702451703547594,\n",
       " 0.14012875536480687,\n",
       " 0.08262598339160838,\n",
       " 0.0432087540809651,\n",
       " 0.02014524080394388,\n",
       " 0.043200337950789015,\n",
       " 0.15537616607716395,\n",
       " 0.05331053409411792,\n",
       " 0.009217080542022117,\n",
       " 0.02223379474412427,\n",
       " 0.2249856626941252,\n",
       " 0.011799589385459637,\n",
       " 0.05555809300301742,\n",
       " 0.04294836065043297,\n",
       " 0.04,\n",
       " 0.5304166666666668,\n",
       " 0.022536531595455878,\n",
       " 0.0189654684097763,\n",
       " 0.014782468572123642,\n",
       " 0.74,\n",
       " 0.008744129968345594,\n",
       " 0.11263040926257605,\n",
       " 0.011806557582333193,\n",
       " 0.033256792380894476,\n",
       " 0.02961336367633268,\n",
       " 0.5167884994907054,\n",
       " 0.10559532933465579,\n",
       " 0.0012618999754260732,\n",
       " 0.011727329929827066,\n",
       " 0.10056877773295683,\n",
       " 0.05212044573682609,\n",
       " 0.013321515733237034,\n",
       " 0.0016939118904439093,\n",
       " 0.4829175492841387,\n",
       " 0.18832666577269208,\n",
       " 0.08304880411571734,\n",
       " 0.014832440160168795,\n",
       " 0.12324470788716449,\n",
       " 0.03789122212258551,\n",
       " 0.0045550430762393455,\n",
       " 0.03425174942319526,\n",
       " 0.04035304219589934,\n",
       " 0.07,\n",
       " 0.031054732088548375,\n",
       " 0.7058653846153845,\n",
       " 0.6586153846153846,\n",
       " 0.04648016432198842,\n",
       " 0.04457609225307941,\n",
       " 0.002400275738028248,\n",
       " 0.292134144213826,\n",
       " 0.11254937304075234,\n",
       " 0.42173538713301156,\n",
       " 0.09068436512638231,\n",
       " 0.05159043441739788,\n",
       " 0.005031923473687095,\n",
       " 0.12422292009713405,\n",
       " 0.024820137076008275,\n",
       " 0.0013388371864643087,\n",
       " 0.0004851045264346497,\n",
       " 0.05331228186721801,\n",
       " 0.0915839436425614,\n",
       " 0.18622912070595654,\n",
       " 0.03797784056868223,\n",
       " 0.01338401584541259,\n",
       " 0.06492430716785125,\n",
       " 0.02245686508274978,\n",
       " 0.014844242636777456,\n",
       " 0.0707350639711434,\n",
       " 0.10096045197740114,\n",
       " 0.03902155895602042,\n",
       " 0.002998561980239662,\n",
       " 0.3233660979604241,\n",
       " 0.0625657341304911,\n",
       " 0.81,\n",
       " 0.0429063337521821,\n",
       " 0.052150089032848665,\n",
       " 6.461798015678185e-05,\n",
       " 0.09349028909174066,\n",
       " 0.014155925682260838,\n",
       " 0.6600250312891114,\n",
       " 0.042633186537673694,\n",
       " 0.0011673243607961056,\n",
       " 0.01286272117581539,\n",
       " 0.07097781130750427,\n",
       " 0.03271175993970215,\n",
       " 0.04183029210383239,\n",
       " 0.03453976009091167,\n",
       " 0.795,\n",
       " 0.022744227323837317,\n",
       " 0.032727082244446815,\n",
       " 0.0140991234415115,\n",
       " 0.79,\n",
       " 0.034183686288755795,\n",
       " 0.03419695553804629,\n",
       " 0.59048,\n",
       " 0.04370208351550721,\n",
       " 0.07587259937103863,\n",
       " 0.63,\n",
       " 0.03025,\n",
       " 0.0017553410286171294,\n",
       " 0.71,\n",
       " 0.0828692506824034,\n",
       " 0.65,\n",
       " 0.02119511410767576,\n",
       " 0.04964492230520207,\n",
       " 0.5306279650436954,\n",
       " 0.07618371413236871,\n",
       " 0.025489083894832367,\n",
       " 0.020344827586206895,\n",
       " 0.0012721702619822783,\n",
       " 0.05452121014206877,\n",
       " 0.010921954286133392,\n",
       " 0.75,\n",
       " 0.0006295374111924461,\n",
       " 0.77,\n",
       " 0.042340044621822684,\n",
       " 0.5202491582491582,\n",
       " 0.020487093571605858,\n",
       " 0.05216534040671972,\n",
       " 0.04048924490235759,\n",
       " 0.865,\n",
       " 0.04128779418546281,\n",
       " 0.010137121212121212,\n",
       " 0.08513759100452473,\n",
       " 0.5426467661691542,\n",
       " 0.013108859189489466,\n",
       " 0.004845147702723534,\n",
       " 0.060419038583175204,\n",
       " 0.24077361853832444,\n",
       " 0.07129106697476387,\n",
       " 0.053157616375641474,\n",
       " 0.05079746031746032,\n",
       " 0.04585574807768482,\n",
       " 0.0436831667977082,\n",
       " 0.1416666666666667,\n",
       " 0.03063575010271432,\n",
       " 0.08422124273528606,\n",
       " 0.08994092279106061,\n",
       " 0.01074753884979031,\n",
       " 0.43898009950248756,\n",
       " 0.01403779640044957,\n",
       " 0.03435930300743407,\n",
       " 0.022019549160193615,\n",
       " 0.022079628015111884,\n",
       " 0.017200987415142074,\n",
       " 0.76,\n",
       " 0.73,\n",
       " 0.00629092780202155,\n",
       " 0.8,\n",
       " 0.65,\n",
       " 0.6907692307692308,\n",
       " 0.05080314891148895,\n",
       " 0.050661522633744856,\n",
       " 0.7308441558441559,\n",
       " 0.05135305168116964,\n",
       " 0.011367915498952568,\n",
       " 0.020837123005175182,\n",
       " 0.07523040866178121,\n",
       " 0.08051512500705456,\n",
       " 0.014101162038126065,\n",
       " 0.03559057994820652,\n",
       " 0.73,\n",
       " 0.001860759261088757,\n",
       " 0.06328185328185329,\n",
       " 0.03541256143925625,\n",
       " 0.024094052369199422,\n",
       " 0.7214061595255058,\n",
       " 0.010469758367640546,\n",
       " 0.06211359475943505,\n",
       " 0.02240538206164934,\n",
       " 0.0032571288926127634,\n",
       " 0.042934063465321415,\n",
       " 0.1740727122461624,\n",
       " 0.023221575843999136,\n",
       " 0.0442654352357098,\n",
       " 0.010901372302252877,\n",
       " 0.027274493615788317,\n",
       " 0.0013509627438198866,\n",
       " 0.08963970524569952,\n",
       " 0.05453384654650823,\n",
       " 0.042880799175689294,\n",
       " 0.10700886322739869,\n",
       " 0.08179090215048579,\n",
       " 0.041270900886236646,\n",
       " 0.0013946043148456977,\n",
       " 0.011861611097126962,\n",
       " 0.7814285714285714,\n",
       " 0.42188311688311686,\n",
       " 0.6830255673525687,\n",
       " 0.04025,\n",
       " 0.14100218954248367,\n",
       " 0.02473575804532319,\n",
       " 0.05131230014427295,\n",
       " 0.022132523459896514,\n",
       " 0.040376667978919444,\n",
       " 0.10223106499238897,\n",
       " 0.011162332848170597,\n",
       " 0.3314285714285714,\n",
       " 0.0054737989021695806,\n",
       " 0.07069482697740112,\n",
       " 0.011316258987447963,\n",
       " 0.018247677858063277,\n",
       " 0.0016103588920542175,\n",
       " 0.5815066964285714,\n",
       " 0.03029850746268657,\n",
       " 0.03528596851425953,\n",
       " 0.08185780031187692,\n",
       " 0.10169193527999276,\n",
       " 0.030171250904953973,\n",
       " 0.05169880452180872,\n",
       " 0.13425378449793748,\n",
       " 0.02094416801731337,\n",
       " 0.08698280074674178,\n",
       " 0.7752985074626867,\n",
       " 0.09677220832870934,\n",
       " 0.02390129426797911,\n",
       " 0.14028740263228578,\n",
       " 0.011682249516396397,\n",
       " 0.6613453846153845,\n",
       " 0.06104757784804912,\n",
       " 4.625090495397662e-05,\n",
       " 0.76,\n",
       " 0.02237651746331534,\n",
       " 0.024507481337055315,\n",
       " 0.03648632512353087,\n",
       " 0.06398505433395617,\n",
       " 0.04924568853360601,\n",
       " 0.062240965298291956,\n",
       " 0.6855769230769231,\n",
       " 0.0006404825985745917,\n",
       " 0.02,\n",
       " 0.04522313360708706,\n",
       " 0.021736148582055973,\n",
       " 0.011721986462365268,\n",
       " 0.04,\n",
       " 0.06109770068588201,\n",
       " 0.04204367172253379,\n",
       " 0.06597909822295031,\n",
       " 0.2344253447171326,\n",
       " 0.0314402810572384,\n",
       " 0.82,\n",
       " 0.08429522968578322,\n",
       " 0.021515611174314248,\n",
       " 0.016133769399906794,\n",
       " 0.79,\n",
       " 0.0606292411495055,\n",
       " 0.021362072937520703,\n",
       " 0.2534690902084753,\n",
       " 0.021954751869135435,\n",
       " 0.05178909567016868,\n",
       " 0.04457776988164406,\n",
       " 0.023225354398358072,\n",
       " 0.005758469723306839,\n",
       " 0.011326265616714674,\n",
       " 0.058156052352389104,\n",
       " 0.05484533869244244,\n",
       " 0.7414142667666637,\n",
       " 0.013269716372674442,\n",
       " 0.09619738857113848,\n",
       " 0.037487627216899355,\n",
       " 0.022666280640120055,\n",
       " 0.12253977727331229,\n",
       " 0.07229480672072448,\n",
       " 0.10104164640771372,\n",
       " 0.0030275653316788748,\n",
       " 0.002049979354068798,\n",
       " 0.07548433013968145,\n",
       " 0.0227246391148994,\n",
       " 0.05178975773946814,\n",
       " 0.025959567960827493,\n",
       " 0.13397790088168152,\n",
       " 0.03403545655906956,\n",
       " 0.010320908422019834,\n",
       " 0.012113625521700054,\n",
       " 0.04400984426454977,\n",
       " 0.12034647282974159,\n",
       " 0.023463944685975142,\n",
       " 0.29563537204524276,\n",
       " 0.040401843918793076,\n",
       " 0.011193189666425947,\n",
       " 0.011696833797064403,\n",
       " 0.04197679353772089,\n",
       " 0.05,\n",
       " 0.045562621224579304,\n",
       " 0.23,\n",
       " 0.13870672734361747,\n",
       " 0.04070928062057094,\n",
       " 0.05136105188343995,\n",
       " 0.042118723418303555,\n",
       " 0.44,\n",
       " 0.040107057920981966,\n",
       " 0.0036439871093491534,\n",
       " 0.08274604432088935,\n",
       " 0.02291850729450151,\n",
       " 0.03215071817874825,\n",
       " 0.020672018804201137,\n",
       " 0.030894409999020062,\n",
       " 0.012905607028731537,\n",
       " 0.09209832134292566,\n",
       " 0.7702985074626867,\n",
       " 0.005558124228712463,\n",
       " 0.17172619047619048,\n",
       " 0.051452717288759935,\n",
       " 0.04141359562171495,\n",
       " 0.04150754097757832,\n",
       " 0.30643880526994166,\n",
       " 0.07379569314377445,\n",
       " 0.12354331581117295,\n",
       " 0.05113457122341646,\n",
       " 0.05404580758441661,\n",
       " 0.06269177942776247,\n",
       " 0.0023485205461732206,\n",
       " 0.19066666666666665,\n",
       " 0.001052694667832426,\n",
       " 0.0307983682983683,\n",
       " 0.23269167659756793,\n",
       " 0.09891353183007592,\n",
       " 0.76,\n",
       " 0.06959959949256933,\n",
       " 0.14020454545454544,\n",
       " 0.01083233100419197,\n",
       " 0.010616678191151873,\n",
       " 0.014349665300726313,\n",
       " 0.012002207742035885,\n",
       " 0.0014893998551301921,\n",
       " 0.24,\n",
       " 0.027738195949420875,\n",
       " 0.007533460643944827,\n",
       " 0.14955800893887142,\n",
       " 0.028268228557206506,\n",
       " 0.004202962314466043,\n",
       " 0.15123830817927217,\n",
       " 0.642543956043956,\n",
       " 0.5403896103896103,\n",
       " 0.02968877476705134,\n",
       " 0.66,\n",
       " 0.04420860608873561,\n",
       " 0.037122622777020366,\n",
       " 0.05034725634725635,\n",
       " 0.050913197361564216,\n",
       " 0.78,\n",
       " 0.12402163381862369,\n",
       " 0.021822501007428708,\n",
       " 0.02677597884507868,\n",
       " 0.0002123182575751123,\n",
       " 0.031114092166746737,\n",
       " 0.042725455139002104,\n",
       " 0.14199272097336327,\n",
       " 0.8802985074626867,\n",
       " 0.61,\n",
       " 0.042456155960646835,\n",
       " 0.1925675802463215,\n",
       " 0.7205769230769231,\n",
       " 0.10644841277361607,\n",
       " 0.03180652211799378,\n",
       " 0.0034784053878939734,\n",
       " 0.05229773944662653,\n",
       " 0.05451013513513514,\n",
       " 0.04367469630608636,\n",
       " 0.09149560991240499,\n",
       " 0.013900713822218962,\n",
       " 0.0849684396724134,\n",
       " 0.0523609906808326,\n",
       " 0.011576631994590273,\n",
       " 0.030376170694575134,\n",
       " 0.03171722780824524,\n",
       " 0.04378786558726699,\n",
       " 0.011039709188628592,\n",
       " 0.015579124692981706,\n",
       " 0.04012875536480687,\n",
       " 0.11694549480236152,\n",
       " 0.07725578755513628,\n",
       " 0.040708337618143915,\n",
       " 0.24371308016877635,\n",
       " 0.0010720713874365069,\n",
       " 0.02914568740585062,\n",
       " 0.03271094424218725,\n",
       " 0.05380158211640599,\n",
       " 0.04640160924072111,\n",
       " 0.021351270528097425,\n",
       " 0.1330222966580393,\n",
       " 0.014321598825539086,\n",
       " 0.5137130801687764,\n",
       " 0.4916666666666667,\n",
       " 0.01015955468901754,\n",
       " 0.012571881723238296,\n",
       " 0.86,\n",
       " 0.10608818823701859,\n",
       " 0.0860540870168773,\n",
       " 0.6214285714285714,\n",
       " 0.8,\n",
       " 0.021170695044271305,\n",
       " 0.6402985074626867,\n",
       " 0.024540889360736333,\n",
       " 0.11175531772245147,\n",
       " 0.03145328459645398,\n",
       " 0.03449034484867961,\n",
       " 0.68,\n",
       " 0.14257327617422375,\n",
       " 0.017480306453778478,\n",
       " 0.1001405472834938,\n",
       " 0.02170196378377945,\n",
       " 0.04275663090402524,\n",
       " 0.06037974683544304,\n",
       " 0.020285627506593688,\n",
       " 0.08047619047619048,\n",
       " 0.13051541433965622,\n",
       " 0.13224462831668418,\n",
       " 0.07088474664043842,\n",
       " 0.07061872950619097,\n",
       " 0.625,\n",
       " 0.09216086023105437,\n",
       " 0.05477800092970366,\n",
       " 0.0052078760767201105,\n",
       " 0.85,\n",
       " 0.66,\n",
       " 0.020493930402633472,\n",
       " 0.06725454154452257,\n",
       " 0.64,\n",
       " 0.5251582712920428,\n",
       " 0.0008843225508643682,\n",
       " 0.008833431529212059,\n",
       " 0.02136645060041141,\n",
       " 0.04199225311697111,\n",
       " 0.0042750585815632,\n",
       " 0.06275162395962451,\n",
       " 0.07200102936899558,\n",
       " 0.1405667784648378,\n",
       " 0.027213372279553213,\n",
       " 0.46119423667987275,\n",
       " 0.3903191489361702,\n",
       " 0.570744126659857,\n",
       " 0.93,\n",
       " 0.025301701299776155,\n",
       " 0.03522144884071313,\n",
       " 0.022585038134581924,\n",
       " 0.12078135198135198,\n",
       " 0.061993199929322534,\n",
       " 0.042161653150510514,\n",
       " 0.7,\n",
       " 0.054386020635680835,\n",
       " 0.004361435073549678,\n",
       " 0.013734602014726238,\n",
       " 0.13309680294520385,\n",
       " 0.06410380352582877,\n",
       " 0.065793069928824,\n",
       " 0.013747963093642625,\n",
       " 0.03493021370660758,\n",
       " 0.0007566358371868095,\n",
       " 0.07196650793650793,\n",
       " 0.0658345823005991,\n",
       " 0.015574609593928338,\n",
       " 0.06311080972473376,\n",
       " 0.07367137899647287,\n",
       " 0.030618990384615383,\n",
       " 0.08139617984255185,\n",
       " 0.014360708944339766,\n",
       " 0.07264945117968963,\n",
       " 0.060454842321328604,\n",
       " 0.15398631699555673,\n",
       " 0.08642626890463574,\n",
       " 0.0015557045654016975,\n",
       " 0.14132146945349144,\n",
       " 0.22048093459052365,\n",
       " 0.06645667207349383,\n",
       " 5.703139176193068e-05,\n",
       " 0.02335079785486427,\n",
       " 0.020373335739705976,\n",
       " 0.03130021330629052,\n",
       " 0.008161248182421463,\n",
       " 0.011885970801112821,\n",
       " 0.008806528324371241,\n",
       " 0.011876337621542585,\n",
       " 0.0006002841723002162,\n",
       " 0.8268779918380433,\n",
       " 0.695,\n",
       " 0.08864641668885229,\n",
       " 0.04142909350159132,\n",
       " 0.08333950698666819,\n",
       " 0.0016857969364003195,\n",
       " 0.0410603112077748,\n",
       " 0.13304001273358515,\n",
       " 0.005717519312516823,\n",
       " 0.035141989049348434,\n",
       " 0.029132728341490152,\n",
       " 0.18090997770345596,\n",
       " 0.05322490544263443,\n",
       " 0.03468251321095776,\n",
       " 0.030486111111111113,\n",
       " 0.0682663471726415,\n",
       " 0.20053883879782688,\n",
       " 0.04193365559001212,\n",
       " 0.03126327160548609,\n",
       " 0.6105168539325843,\n",
       " 0.004897293395773241,\n",
       " 0.46,\n",
       " 0.011672887225146868,\n",
       " 0.1925,\n",
       " 0.5766935483870967,\n",
       " 0.022077945630964848,\n",
       " 0.09086568177483588,\n",
       " 0.17728327590986495,\n",
       " 0.1449642452443523,\n",
       " 0.1275802021816643,\n",
       " 0.011515851008124665,\n",
       " 0.08404241609365219,\n",
       " 0.06110559956888397,\n",
       " 0.02091268451944744,\n",
       " 0.03611675418604382,\n",
       " 0.06568361615749113,\n",
       " 0.010297235257739458,\n",
       " 0.11279761365201402,\n",
       " 0.8,\n",
       " 0.2922001386841139,\n",
       " 0.04430964557472099,\n",
       " 0.02748153097739734,\n",
       " 0.041755887933513015,\n",
       " 0.5106070195627158,\n",
       " 0.48223437500000005,\n",
       " 0.0303599102182376,\n",
       " 0.0018384954635569447,\n",
       " 0.14321788791274084,\n",
       " 0.13905410236604074,\n",
       " 0.83048,\n",
       " 0.0034202514580425497,\n",
       " 0.03238667243513496,\n",
       " 0.21291760694662482,\n",
       " 0.016943243267433124,\n",
       " 0.08267110032646206,\n",
       " 0.021246497339525054,\n",
       " 0.046807917852591106,\n",
       " 0.012000576241060506,\n",
       " 0.04717753551395973,\n",
       " 0.06056104926870663,\n",
       " 0.022393064812506584,\n",
       " 0.04127821791049309,\n",
       " 0.040624106865486176,\n",
       " 0.5710464135021097,\n",
       " 0.018050849074581238,\n",
       " 0.021845245172865804,\n",
       " 0.625,\n",
       " 0.012069889577197268,\n",
       " 0.05935804168380315,\n",
       " 0.26502631578947367,\n",
       " 0.03134917557054886,\n",
       " 0.040754640600547995,\n",
       " 0.1517741004344246,\n",
       " 0.06125976164760576,\n",
       " 0.091754968654531,\n",
       " 0.7806034567901234,\n",
       " 0.16598672004687046,\n",
       " 0.5192723484380788,\n",
       " 0.3938703196347032,\n",
       " 0.02173414068154686,\n",
       " 0.05,\n",
       " 0.023811379973401225,\n",
       " 0.03180417794970986,\n",
       " 0.5011294721376923,\n",
       " 0.021053515089909717,\n",
       " 0.014623353140566888,\n",
       " 0.13019607843137254,\n",
       " 0.011641262766243743,\n",
       " 0.09140125261210728,\n",
       " 0.5121663785332009,\n",
       " 0.7,\n",
       " 0.79,\n",
       " 0.014587580200890914,\n",
       " 0.10191970333587981,\n",
       " 0.08249349827719994,\n",
       " 0.09816055594411491,\n",
       " 0.031506182859371304,\n",
       " 0.029368645145254408,\n",
       " 0.03189183846738891,\n",
       " 0.025550149439386514,\n",
       " 0.09364227886203678,\n",
       " 0.05407826999746164,\n",
       " 0.026810665305442197,\n",
       " 0.0320500026178142,\n",
       " 0.0003106286748077793,\n",
       " 0.07110682492176444,\n",
       " 0.05260999148836067,\n",
       " 0.25,\n",
       " 0.1136238084016956,\n",
       " 0.54,\n",
       " 0.05619513777347878,\n",
       " 0.03183791208791208,\n",
       " 0.010855327238452596,\n",
       " 0.19268302778721133,\n",
       " 0.021806708060439283,\n",
       " 0.001675712503151882,\n",
       " 0.02045564147034735,\n",
       " 0.2942447916666666,\n",
       " 0.69,\n",
       " 0.14175402225358147,\n",
       " 0.02161163935265363,\n",
       " 0.05071291960009632,\n",
       " 0.01386174887746076,\n",
       " 0.021377610332857455,\n",
       " 0.003299103997280753,\n",
       " 0.08892597292754263,\n",
       " 0.5914285714285714,\n",
       " 0.73,\n",
       " 0.051428604426669564,\n",
       " 0.025463595195108737,\n",
       " 0.013268568775784462,\n",
       " 0.045414738649914084,\n",
       " 0.09520877769593084,\n",
       " 0.09007017249804479,\n",
       " 0.19395351868435085,\n",
       " 0.815,\n",
       " 0.07279053463317181,\n",
       " 0.55,\n",
       " 0.012618047580308546,\n",
       " 0.08171107705013955,\n",
       " 0.0006472392675916752,\n",
       " 0.0024624404965390826,\n",
       " 0.04520586281249897,\n",
       " 0.015173411534701857,\n",
       " 0.22039661599028354,\n",
       " 0.785078125,\n",
       " 0.02707855990948994,\n",
       " 0.0008039150475304345,\n",
       " 0.04132230071515786,\n",
       " 0.08107446392545911,\n",
       " 0.02,\n",
       " 0.31342716116837027,\n",
       " 0.56,\n",
       " 0.03870418279326309,\n",
       " 0.17207859686568816,\n",
       " 0.53,\n",
       " 0.12535678459934424,\n",
       " 0.0329818418418978,\n",
       " 0.16405037346031828,\n",
       " 0.018466736098441083,\n",
       " 0.004014068083529222,\n",
       " 0.04066425435970956,\n",
       " 0.02072927152132724,\n",
       " 0.06091871291055309,\n",
       " 0.14044672897196261,\n",
       " 0.041685969799982826,\n",
       " 0.3,\n",
       " 0.05127482466464431,\n",
       " 0.1,\n",
       " 0.05054879939914732,\n",
       " 0.77,\n",
       " 0.8,\n",
       " 0.04135297078719777,\n",
       " 0.06431435848379354,\n",
       " 0.01513086790760381,\n",
       " 0.8,\n",
       " 0.023326223531812906,\n",
       " 0.013322853616971265,\n",
       " 0.07170372860866758,\n",
       " 0.10032319707544034,\n",
       " 0.5329411764705883,\n",
       " 0.7401587301587301,\n",
       " 0.024775903791433133,\n",
       " 0.0338781816232349,\n",
       " 0.17295475666422105,\n",
       " 0.3667447916666666,\n",
       " 0.7901587301587302,\n",
       " 0.0203555388544485,\n",
       " 0.0012154432390219753,\n",
       " 0.03180539349925528,\n",
       " 0.05213131808461984,\n",
       " 0.2906736478895844,\n",
       " 0.08572746591981245,\n",
       " 0.006706307433655883,\n",
       " 0.252229528282622,\n",
       " 0.040121706443331816,\n",
       " 0.8302985074626866,\n",
       " 0.92,\n",
       " 0.1142602495543672,\n",
       " 0.09290083970903601,\n",
       " 0.805,\n",
       " 0.72,\n",
       " 0.01041996607866915,\n",
       " 0.1722987980010646,\n",
       " 0.05267503866735246,\n",
       " 0.09820178889309343,\n",
       " 0.08471510604125547,\n",
       " 0.006277545104918158,\n",
       " 0.04241457093722019,\n",
       " 0.03317860406269125,\n",
       " 0.021575746816425413,\n",
       " 0.0014909141419093374,\n",
       " 0.0280735915167611,\n",
       " 0.007759834561715739,\n",
       " 0.013355186415651882,\n",
       " 0.2110903123116335,\n",
       " 0.023346612222770048,\n",
       " 0.03258173546669674,\n",
       " 0.020666666666666663,\n",
       " 0.02159479995242806,\n",
       " 0.004979347852486972,\n",
       " 0.05305847560711091,\n",
       " 0.060919430794430796,\n",
       " 0.11109616573902288,\n",
       " 0.0325,\n",
       " 0.011384339602519328,\n",
       " 0.028090637759310852,\n",
       " 0.010807161914731307,\n",
       " 0.043097723274134664,\n",
       " 0.02019725034824554,\n",
       " 0.020520977491595437,\n",
       " 0.05556710947219372,\n",
       " 0.010865680731053252,\n",
       " 0.0236145376673924,\n",
       " 0.600386002886003,\n",
       " 0.025181339106140236,\n",
       " 0.23002688172043012,\n",
       " 0.07621205426438468,\n",
       " 0.040893907410856564,\n",
       " 0.8,\n",
       " 0.09507042883547687,\n",
       " 0.08520374762815155,\n",
       " 0.011089968245577158,\n",
       " 0.030661522633744855,\n",
       " 0.09035357659859672,\n",
       " 0.045051768220259455,\n",
       " 0.022719202959149067,\n",
       " 0.6711915384615385,\n",
       " 0.12052873181718096,\n",
       " 0.01077866841258586,\n",
       " 0.8,\n",
       " 0.09240028452595314,\n",
       " 0.7303333333333333,\n",
       " 0.68,\n",
       " 0.022801635475794328,\n",
       " 0.7116949152542372,\n",
       " 0.031154195501417722,\n",
       " 0.004707037185232091,\n",
       " 0.05323460385043812,\n",
       " 0.020477268579520036,\n",
       " 0.12003412969283277,\n",
       " 0.03339110572447488,\n",
       " 0.010735790443115045,\n",
       " 0.004889729437468095,\n",
       " 0.09729526225763514,\n",
       " 0.09735573892013077,\n",
       " 0.05453503830267125,\n",
       " 0.625,\n",
       " 0.02814208137027419,\n",
       " 0.021344908285008183,\n",
       " 0.41157824284825834,\n",
       " 0.040341531755915316,\n",
       " 0.041863885886850076,\n",
       " 0.03883147382804286,\n",
       " 0.05156176411222499,\n",
       " 0.1803448275862069,\n",
       " 0.10683366641412449,\n",
       " 0.11178815066753994,\n",
       " 0.1818387328236605,\n",
       " 0.09476944957883043,\n",
       " 0.03849495406279031,\n",
       " 0.77,\n",
       " 0.03439814550432206,\n",
       " 0.06003412969283277,\n",
       " 0.08550701230053441,\n",
       " 0.73,\n",
       " 0.04169028213166144,\n",
       " 0.049995118907683225,\n",
       " 0.011703906669422332,\n",
       " 0.02221620562351826,\n",
       " 0.00026618761381473616,\n",
       " 0.03144100892647404,\n",
       " 0.026409808483776182,\n",
       " 0.15317555147058826,\n",
       " 0.06356467919621302,\n",
       " 0.20466760287493024,\n",
       " 0.0417731836270932,\n",
       " 0.14381817226008975,\n",
       " 0.05207951801877404,\n",
       " 0.04383602800927741,\n",
       " 0.72,\n",
       " 0.14108700020092424,\n",
       " 0.1789478979508411,\n",
       " 0.019612715091675878,\n",
       " 0.07089147248975142,\n",
       " 0.09054378531073447,\n",
       " 0.5098602261048304,\n",
       " 0.022378565630520077,\n",
       " 0.16254140078875529,\n",
       " 0.061629378890001085,\n",
       " 0.05473729414949526,\n",
       " 0.4917948717948718,\n",
       " 0.022355728366199826,\n",
       " 0.013311677837971244,\n",
       " 0.05124986417657046,\n",
       " 0.04374154735421579,\n",
       " 0.09464196204797708,\n",
       " 0.03012875536480687,\n",
       " 0.08804090601757945,\n",
       " 0.002340988716487182,\n",
       " 0.05243409950499791,\n",
       " 0.04084243360805861,\n",
       " 0.031089454679543525,\n",
       " 0.74,\n",
       " 0.0711768018018018,\n",
       " 0.0017936943695035384,\n",
       " 0.3145833333333333,\n",
       " 0.1524188179067515,\n",
       " 0.02227167006000049,\n",
       " 0.04072556522870266,\n",
       " 0.01890480028953083,\n",
       " 0.057711293156914506,\n",
       " 0.09039430819349682,\n",
       " 0.060354808590102706,\n",
       " 0.05216986928511403,\n",
       " 0.020993142154464853,\n",
       " 0.11011963077320289,\n",
       " ...]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "y_pred_proba = clf.predict_proba(X_val)\n",
    "y_pred_proba = [sublist[1] for sublist in y_pred_proba]\n",
    "\n",
    "df_results = pd.DataFrame()\n",
    "df_results['y_pred'] = y_pred\n",
    "df_results['y_true'] = y_val\n",
    "df_results['predict_proba'] = y_pred_proba\n",
    "df_results['average cost min'] = list(averagecostmin)\n",
    "#Profit_top_k(df_results)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bc12e42e-2119-4b24-9c2c-810bf19251b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test = encoded_test.drop(columns = 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "51d88a9e-0759-4aa2-9103-4e22cc6a19a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Assuming 'data' is your dataset with missing values\n",
    "# Create an instance of SimpleImputer with strategy='median'\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Fit the imputer on the data\n",
    "imputer.fit(X_train)\n",
    "\n",
    "# Transform the data by replacing missing values with the median\n",
    "test_clean = imputer.transform(encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "082e007f-3645-41d0-8d28-d0b9f498c3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test = pd.DataFrame(test_clean, columns= encoded_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7a31bba0-6591-49d0-81e8-d73ce0e938f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>L_O_S</th>\n",
       "      <th>Dropped_Calls</th>\n",
       "      <th>OffPeak_calls_Sum</th>\n",
       "      <th>OffPeak_mins_Sum</th>\n",
       "      <th>Weekend_calls_Sum</th>\n",
       "      <th>Weekend_mins_Sum</th>\n",
       "      <th>AvePeak</th>\n",
       "      <th>AveOffPeak</th>\n",
       "      <th>AveWeekend</th>\n",
       "      <th>...</th>\n",
       "      <th>Handset_ASAD90</th>\n",
       "      <th>Handset_BS110</th>\n",
       "      <th>Handset_BS210</th>\n",
       "      <th>Handset_CAS30</th>\n",
       "      <th>Handset_CAS60</th>\n",
       "      <th>Handset_S50</th>\n",
       "      <th>Handset_S80</th>\n",
       "      <th>Handset_SOP10</th>\n",
       "      <th>Handset_SOP20</th>\n",
       "      <th>Handset_WC95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.946100</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.174120</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.024478</td>\n",
       "      <td>0.008166</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.013685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.461915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166071</td>\n",
       "      <td>0.505744</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.085822</td>\n",
       "      <td>0.028541</td>\n",
       "      <td>0.008096</td>\n",
       "      <td>0.036838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.349800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.139979</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>0.116623</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>0.015865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.371024</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.328806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014754</td>\n",
       "      <td>0.010196</td>\n",
       "      <td>-0.002175</td>\n",
       "      <td>0.064680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.326274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130357</td>\n",
       "      <td>0.129393</td>\n",
       "      <td>0.103774</td>\n",
       "      <td>0.229439</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>0.009914</td>\n",
       "      <td>0.020227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.627258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.039367</td>\n",
       "      <td>0.424528</td>\n",
       "      <td>0.515971</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>0.011009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>0.102941</td>\n",
       "      <td>0.266872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001786</td>\n",
       "      <td>0.067495</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.140253</td>\n",
       "      <td>-0.002266</td>\n",
       "      <td>0.009441</td>\n",
       "      <td>0.065240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.941105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.255168</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.165996</td>\n",
       "      <td>0.006873</td>\n",
       "      <td>0.076621</td>\n",
       "      <td>0.078978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>0.132353</td>\n",
       "      <td>0.683543</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.135714</td>\n",
       "      <td>0.180316</td>\n",
       "      <td>-0.009434</td>\n",
       "      <td>0.090110</td>\n",
       "      <td>-0.003299</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.026010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.802056</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.522538</td>\n",
       "      <td>0.273585</td>\n",
       "      <td>0.316715</td>\n",
       "      <td>0.040734</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.019093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Age     L_O_S  Dropped_Calls  OffPeak_calls_Sum  OffPeak_mins_Sum  \\\n",
       "0     0.117647  0.946100       0.200000           0.196429          0.174120   \n",
       "1     0.617647  0.461915       0.000000           0.166071          0.505744   \n",
       "2     0.235294  0.349800       0.000000           0.160714          0.139979   \n",
       "3     0.205882  0.371024       0.333333           0.225000          0.328806   \n",
       "4     0.323529  0.326274       0.000000           0.130357          0.129393   \n",
       "...        ...       ...            ...                ...               ...   \n",
       "1677  0.294118  0.627258       0.000000           0.014286          0.039367   \n",
       "1678  0.102941  0.266872       0.000000          -0.001786          0.067495   \n",
       "1679  0.323529  0.941105       0.000000           0.037500          0.255168   \n",
       "1680  0.132353  0.683543       0.133333           0.135714          0.180316   \n",
       "1681  0.044118  0.802056       0.133333           0.385714          0.522538   \n",
       "\n",
       "      Weekend_calls_Sum  Weekend_mins_Sum   AvePeak  AveOffPeak  AveWeekend  \\\n",
       "0              0.075472          0.024478  0.008166    0.000262    0.013685   \n",
       "1              0.075472          0.085822  0.028541    0.008096    0.036838   \n",
       "2              0.094340          0.116623  0.002506    0.008828    0.015865   \n",
       "3              0.000000          0.014754  0.010196   -0.002175    0.064680   \n",
       "4              0.103774          0.229439  0.007551    0.009914    0.020227   \n",
       "...                 ...               ...       ...         ...         ...   \n",
       "1677           0.424528          0.515971  0.000682    0.004807    0.011009   \n",
       "1678           0.018868          0.140253 -0.002266    0.009441    0.065240   \n",
       "1679           0.018868          0.165996  0.006873    0.076621    0.078978   \n",
       "1680          -0.009434          0.090110 -0.003299    0.008065    0.026010   \n",
       "1681           0.273585          0.316715  0.040734    0.001697    0.019093   \n",
       "\n",
       "      ...  Handset_ASAD90  Handset_BS110  Handset_BS210  Handset_CAS30  \\\n",
       "0     ...             0.0            0.0            0.0            0.0   \n",
       "1     ...             0.0            1.0            0.0            0.0   \n",
       "2     ...             0.0            0.0            0.0            0.0   \n",
       "3     ...             0.0            0.0            0.0            0.0   \n",
       "4     ...             0.0            0.0            0.0            0.0   \n",
       "...   ...             ...            ...            ...            ...   \n",
       "1677  ...             0.0            1.0            0.0            0.0   \n",
       "1678  ...             0.0            1.0            0.0            0.0   \n",
       "1679  ...             0.0            0.0            0.0            0.0   \n",
       "1680  ...             0.0            1.0            0.0            0.0   \n",
       "1681  ...             0.0            0.0            0.0            0.0   \n",
       "\n",
       "      Handset_CAS60  Handset_S50  Handset_S80  Handset_SOP10  Handset_SOP20  \\\n",
       "0               0.0          0.0          0.0            0.0            0.0   \n",
       "1               0.0          0.0          0.0            0.0            0.0   \n",
       "2               0.0          0.0          0.0            0.0            0.0   \n",
       "3               0.0          0.0          0.0            0.0            0.0   \n",
       "4               0.0          0.0          0.0            0.0            0.0   \n",
       "...             ...          ...          ...            ...            ...   \n",
       "1677            0.0          0.0          0.0            0.0            0.0   \n",
       "1678            0.0          0.0          0.0            0.0            0.0   \n",
       "1679            0.0          1.0          0.0            0.0            0.0   \n",
       "1680            0.0          0.0          0.0            0.0            0.0   \n",
       "1681            0.0          0.0          0.0            0.0            0.0   \n",
       "\n",
       "      Handset_WC95  \n",
       "0              1.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              1.0  \n",
       "4              1.0  \n",
       "...            ...  \n",
       "1677           0.0  \n",
       "1678           0.0  \n",
       "1679           0.0  \n",
       "1680           0.0  \n",
       "1681           1.0  \n",
       "\n",
       "[1682 rows x 34 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b146a560-ca11-4fce-b866-bc2421829922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "12fc8573-659e-4296-9d34-cf2ae375d2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_test = clf.predict_proba(encoded_test)\n",
    "y_pred_proba_test = [sublist[1] for sublist in y_pred_proba_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f3095b37-af6f-4f87-888a-04bccec5f6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1682\n"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame()\n",
    "df_results[\"ID\"] = idtest\n",
    "df_results[\"PRED\"] = y_pred_proba_test\n",
    "print(len(y_pred_proba_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a8a310d6-d6e1-4b32-a282-3ec26e15c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"Model_Results_1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcf7f7d-8e0a-4554-abec-ad5a5db8f265",
   "metadata": {},
   "source": [
    "## model 2: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "74c31feb-90a8-4c61-9044-969658ec6d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(encoded_test)\n",
    "\n",
    "\n",
    "#accuracy = accuracy_score(y_val, y_pred)\n",
    "#print(\"Decision Tree Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "78553e5b-f227-4dac-9ac3-967bd8e20aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b65ba1ce-1296-4281-9d56-9db5bf22173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame()\n",
    "df_results['ID'] = idtest\n",
    "df_results['PRED'] = y_pred\n",
    "df_results.to_csv(\"Model_results_2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7576214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decision_Tree():\n",
    "    \n",
    "    clf = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    y_pred = clf.predict(encoded_test)\n",
    "    \n",
    "    df_results = pd.DataFrame()\n",
    "    df_results['ID'] = idtest\n",
    "    df_results['PRED'] = y_pred\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731be0cb-7cc4-4aac-ad2b-0e8df5e9712f",
   "metadata": {},
   "source": [
    "## model 3: Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bab61066-59b1-492b-97dd-2fb3850fb006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(encoded_test)\n",
    "\n",
    "#accuracy = accuracy_score(y_val, y_pred)\n",
    "#print(\"Logistic Regression Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e008198d-5970-42d5-b561-378f6e4b1ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PRED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K751808</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K837351</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K548114</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K736156</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K508080</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>K588314</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>K826807</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>K982731</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>K623037</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>K883413</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  PRED\n",
       "0     K751808   0.0\n",
       "1     K837351   0.0\n",
       "2     K548114   0.0\n",
       "3     K736156   0.0\n",
       "4     K508080   0.0\n",
       "...       ...   ...\n",
       "1677  K588314   0.0\n",
       "1678  K826807   0.0\n",
       "1679  K982731   0.0\n",
       "1680  K623037   0.0\n",
       "1681  K883413   0.0\n",
       "\n",
       "[1682 rows x 2 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame()\n",
    "df_results['ID'] = idtest\n",
    "df_results['PRED'] = y_pred\n",
    "df_results.to_csv(\"Model_results_3.csv\", index = False)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "924f886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg():\n",
    "    logreg = LogisticRegression()\n",
    "\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = logreg.predict(encoded_test)\n",
    "    \n",
    "    df_results = pd.DataFrame()\n",
    "    df_results['ID'] = idtest\n",
    "    df_results['PRED'] = y_pred\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa3aeae-9ec2-4b90-a1c3-370efcb9f007",
   "metadata": {},
   "source": [
    "## model 4: Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "376a08fa-913e-458f-b420-9ae3cb571112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), )\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "y_pred = mlp.predict(encoded_test)\n",
    "\n",
    "#accuracy = accuracy_score(y_val, y_pred)\n",
    "#print(\"Neural Network Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1678c094-5d16-4b4e-8c8b-2c0361216317",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame()\n",
    "df_results['ID'] = idtest\n",
    "df_results['PRED'] = y_pred\n",
    "df_results.to_csv(\"Model_results_4.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "26f3a6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network():\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(100,), )\n",
    "\n",
    "    mlp.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = mlp.predict(encoded_test)\n",
    "    \n",
    "    df_results = pd.DataFrame()\n",
    "    df_results['ID'] = idtest\n",
    "    df_results['PRED'] = y_pred\n",
    "    \n",
    "    return df_results\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f51ace",
   "metadata": {},
   "source": [
    "# Evaluating classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ed6a1cfb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__() got an unexpected keyword argument 'cv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n3/j9s0z6s92fd1_xkmg3xk0twh0000gn/T/ipykernel_74929/1541509998.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcv_results_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __call__() got an unexpected keyword argument 'cv'"
     ]
    }
   ],
   "source": [
    "custom_scorer = make_scorer(Profit_top_k, greater_is_better=True, needs_threshold=False )\n",
    "\n",
    "kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "cv_results_N = custom_scorer(model, X_train, y_train, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b7992e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# To ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "models = {\"Logistic Regression\": LogisticRegression(), \"Neural networks\": MLPClassifier(hidden_layer_sizes=(100,), )\n",
    ",\n",
    "          \"Decision Tree\": DecisionTreeClassifier()}\n",
    "\n",
    "\n",
    "classifiers = [('Logistic Regression', logreg), ('K Nearest Neighbours', knn), ('Classification Tree', clf)]\n",
    "\n",
    "\n",
    "results = []\n",
    "profit = []\n",
    "\n",
    "for model in models.values():\n",
    "    kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
    "    \n",
    "    \n",
    "    cv_results_N = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "    \n",
    "    \n",
    "    results.append(cv_results_N)\n",
    "\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Profit_top_k(df_results, k = 20, var = 'average cost min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9b0695b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n3/j9s0z6s92fd1_xkmg3xk0twh0000gn/T/ipykernel_74929/2740991843.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mProfit_top_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/n3/j9s0z6s92fd1_xkmg3xk0twh0000gn/T/ipykernel_74929/2740991843.py\u001b[0m in \u001b[0;36mProfit_top_k\u001b[0;34m(df_results, k, var)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mprofit_top_k_scorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mProfit_top_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'average cost min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0msorted_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"predict_proba\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0msum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   6320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6321\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6322\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6324\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1838\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1839\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'predict_proba'"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "y_pred_proba = clf.predict_proba(X_val)\n",
    "y_pred_proba = [sublist[1] for sublist in y_pred_proba]\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def Profit_top_k_1(estimator, X_val, y_val):\n",
    "    k = 20\n",
    "    var = 'average cost min'\n",
    "    \n",
    "    estimator.fit(X_val, y_val)\n",
    "    \n",
    "    y_pred = estimator.predict(X_val)\n",
    "    \n",
    "    y_pred_proba = estimator.predict_proba(X_val)\n",
    "    y_pred_proba = [sublist[1] for sublist in y_pred_proba]\n",
    "\n",
    "    averagecostmin = X_val['average cost min']\n",
    "    \n",
    "    df_results = pd.DataFrame()\n",
    "    df_results['y_pred'] = y_pred\n",
    "    df_results['y_true'] = y_val\n",
    "    df_results['predict_proba'] = y_pred_proba\n",
    "    df_results['average cost min'] = list(averagecostmin)\n",
    "    \n",
    "    sorted_df = df_results.sort_values(by= \"predict_proba\", ascending = False)\n",
    "    sum = 0\n",
    "    for i in range(0, k):\n",
    "        if df_results['y_true'][i] == df_results['y_pred'][i]:\n",
    "            sum += df_results[var][i]\n",
    "            \n",
    "            \n",
    "    return sum\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "profit_top_k_scorer = make_scorer(Profit_top_k_1, greater_is_better=True)\n",
    "\n",
    "# Wrap the custom metric function using make_scorer\n",
    "profit_top_k_scorer\n",
    "def Profit_top_k(df_results, k = 20, var = 'average cost min'):\n",
    "    sorted_df = df_results.sort_values(by= \"predict_proba\", ascending = False)\n",
    "    sum = 0\n",
    "    for i in range(0, k):\n",
    "        if df_results['y_true'][i] == df_results['y_pred'][i]:\n",
    "            sum += df_results[var][i]\n",
    "    return sum\n",
    "\n",
    "Profit_top_k(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0f3db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_N = cross_val_score(knn, X_val, y_val,cv=2, scoring=profit_top_k_scorer)\n",
    "cv_results_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8ddd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Profit_top_k_1(knn, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e5b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring=Profit_top_k_1)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "\n",
    "# Calculate and print the mean score\n",
    "print(\"Mean profit score:\", np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6224a2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# To ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "models = {\"Logistic Regression\": logreg, \"Neural networks\": knn\n",
    ",\n",
    "          \"Decision Tree\": clf}\n",
    "\n",
    "\n",
    "classifiers = [('Logistic Regression', logreg), ('K Nearest Neighbours', knn), ('Classification Tree', clf)]\n",
    "\n",
    "\n",
    "results = []\n",
    "profit = []\n",
    "\n",
    "for model in models.values():\n",
    "    kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
    "    \n",
    "    \n",
    "    cv_results_N = cross_val_score(model, X_val, y_val,cv=kf, scoring=profit_top_k_scorer)\n",
    "    \n",
    "    \n",
    "    results.append(cv_results_N)\n",
    "\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e585ea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Neural Networks\": MLPClassifier(hidden_layer_sizes=(100,)),\n",
    "    \"Decision Tree\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "# Define classifiers for plotting\n",
    "classifiers = list(models.keys())\n",
    "\n",
    "results = []\n",
    "profits = []\n",
    "\n",
    "# Iterate over models\n",
    "for model_name, model in models.items():\n",
    "    kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_results = cross_val_score(model, X_val, y_val, cv=kf, scoring=profit_top_k_scorer)\n",
    "\n",
    "    #cv_results = cross_val_score(model, X_val, y_val, cv=kf, scoring=profit_top_k_scorer)\n",
    "    results.append(cv_results)\n",
    "    \n",
    "    # Store profit scores for each fold\n",
    "    profits.append(cv_results)\n",
    "    \n",
    "    # Display average profit score for the model\n",
    "    print(f\"Average profit score for {model_name}: {np.mean(cv_results)}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(profits, labels=classifiers)\n",
    "plt.title('Profit Scores of Different Models')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Profit Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd420b39",
   "metadata": {},
   "source": [
    "## Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806c722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import VotingClassifier from sklearn.ensemble\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "\n",
    "classifiers = [('Logistic Regression', logreg), ('K Nearest Neighbours', knn), ('Classification Tree', clf)]\n",
    "\n",
    "# Instantiate a VotingClassifier vc\n",
    "vc = VotingClassifier(estimators=classifiers)     \n",
    "\n",
    "# Fit vc to the training set\n",
    "vc.fit(X_train, y_train)   \n",
    "\n",
    "# Evaluate the test set predictions\n",
    "y_pred = vc.predict(X_val)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print('Voting Classifier: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fef71e9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__() missing 1 required positional argument: 'y_true'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n3/j9s0z6s92fd1_xkmg3xk0twh0000gn/T/ipykernel_74929/3061296934.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Assuming 'average cost min' is the relevant variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy Score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __call__() missing 1 required positional argument: 'y_true'"
     ]
    }
   ],
   "source": [
    "accuracy_scorer = make_scorer(Profit_top_k, greater_is_better=True)\n",
    "\n",
    "\n",
    "accuracy = accuracy_scorer(y_val, y_pred)  # Assuming 'average cost min' is the relevant variable\n",
    "print('Accuracy Score:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "406e1213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Profit_top_k(df_results, k = 20, var = 'average cost min'):\n",
    "    sorted_df = df_results.sort_values(by= \"predict_proba\", ascending = False)\n",
    "    sum = 0\n",
    "    for i in range(0, k):\n",
    "        if df_results['y_true'][i] == df_results['y_pred'][i]:\n",
    "            sum += df_results[var][i]\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0accdd9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2680690369.py, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/n3/j9s0z6s92fd1_xkmg3xk0twh0000gn/T/ipykernel_74929/2680690369.py\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    cv_scores = cross_val_score(vc, X_train, y_train, cv=5, scoring=lambda estimator, X_train, y_train: profit_scorer(estimator, X_train, y_train, df_results= ))\u001b[0m\n\u001b[0m                                                                                                                                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Define your custom scoring function\n",
    "def Profit_top_k(df_results, k=20, var='average cost min'):\n",
    "    sorted_df = df_results.sort_values(by=\"predict_proba\", ascending=False)\n",
    "    total_profit = 0\n",
    "    for i in range(k):\n",
    "        if sorted_df['y_true'].iloc[i] == sorted_df['y_pred'].iloc[i]:\n",
    "            total_profit += sorted_df[var].iloc[i]\n",
    "    return total_profit\n",
    "\n",
    "# Wrap your custom scoring function using make_scorer\n",
    "profit_scorer = make_scorer(Profit_top_k, greater_is_better=True)\n",
    "\n",
    "# Example usage with cross-validation\n",
    "X, y = make_classification(n_samples=100, n_features=20, random_state=42)\n",
    "model = LogisticRegression()\n",
    "# Assume df_results is available\n",
    "# cross_val_score doesn't directly support passing additional arguments to the scoring function,\n",
    "# so you need to use a wrapper function if you want to pass extra parameters.\n",
    "# Here, I'm using a lambda function to pass df_results to the scorer.\n",
    "cv_scores = cross_val_score(vc, X_train, y_train, cv=5, scoring=lambda estimator, X_train, y_train: profit_scorer(estimator, X_train, y_train, df_results= ))\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV Profit:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273c7950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abe96ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5906a1d",
   "metadata": {},
   "source": [
    "# Evaluating classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a9707aa2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'warnings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n3/j9s0z6s92fd1_xkmg3xk0twh0000gn/T/ipykernel_74929/3381307828.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# To ignore all warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m df_res = {\"Logistic Regression\": log_reg(), \"Neural networks\": neural_network()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'warnings' is not defined"
     ]
    }
   ],
   "source": [
    "# To ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "df_res = {\"Logistic Regression\": log_reg(), \"Neural networks\": neural_network()\n",
    ",\n",
    "          \"Decision Tree\": Decision_Tree()}\n",
    "\n",
    "models = {\"Logistic Regression\": LogisticRegression(), \"Neural networks\": MLPClassifier(hidden_layer_sizes=(100,), )\n",
    ",\n",
    "          \"Decision Tree\": DecisionTreeClassifier()}\n",
    "results = []\n",
    "profit = []\n",
    "\n",
    "for model in models.values():\n",
    "    kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
    "    \n",
    "    cv_results = Profit_top_k(model, k = 20, var = 'average cost min')\n",
    "    \n",
    "    results.append(cv_results)\n",
    "\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Profit_top_k(df_results, k = 20, var = 'average cost min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8d63f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6d756a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f031e07",
   "metadata": {},
   "source": [
    "## Regularized regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dff1c9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Connect_Date</th>\n",
       "      <th>L_O_S</th>\n",
       "      <th>Dropped_Calls</th>\n",
       "      <th>tariff</th>\n",
       "      <th>Handset</th>\n",
       "      <th>Peak_calls_Sum</th>\n",
       "      <th>Peak_mins_Sum</th>\n",
       "      <th>OffPeak_calls_Sum</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_Cost</th>\n",
       "      <th>Tariff_OK</th>\n",
       "      <th>average cost min</th>\n",
       "      <th>Peak ratio</th>\n",
       "      <th>OffPeak ratio</th>\n",
       "      <th>Weekend ratio</th>\n",
       "      <th>Nat-InterNat Ratio</th>\n",
       "      <th>high Dropped calls</th>\n",
       "      <th>No Usage</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20/05/98</td>\n",
       "      <td>29.200000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Play 100</td>\n",
       "      <td>BS210</td>\n",
       "      <td>62.0</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>185.0</td>\n",
       "      <td>...</td>\n",
       "      <td>112.386773</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.150531</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.706735</td>\n",
       "      <td>0.046729</td>\n",
       "      <td>0.203034</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>K262360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16/12/96</td>\n",
       "      <td>46.533333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CAT 100</td>\n",
       "      <td>ASAD90</td>\n",
       "      <td>146.0</td>\n",
       "      <td>718.800000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>...</td>\n",
       "      <td>221.546571</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.188988</td>\n",
       "      <td>0.780710</td>\n",
       "      <td>0.178886</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.273249</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>K170160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>46.0</td>\n",
       "      <td>27/08/97</td>\n",
       "      <td>38.066667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CAT 50</td>\n",
       "      <td>WC95</td>\n",
       "      <td>160.0</td>\n",
       "      <td>322.800000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>128.811484</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.239300</td>\n",
       "      <td>0.722633</td>\n",
       "      <td>0.277367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.205025</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>K331610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>59.0</td>\n",
       "      <td>13/07/98</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CAT 50</td>\n",
       "      <td>BS110</td>\n",
       "      <td>84.0</td>\n",
       "      <td>317.400001</td>\n",
       "      <td>57.0</td>\n",
       "      <td>...</td>\n",
       "      <td>111.419646</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.221467</td>\n",
       "      <td>0.662492</td>\n",
       "      <td>0.337508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050090</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>K332460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>25.0</td>\n",
       "      <td>08/01/99</td>\n",
       "      <td>21.433333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Play 300</td>\n",
       "      <td>WC95</td>\n",
       "      <td>14.0</td>\n",
       "      <td>309.600000</td>\n",
       "      <td>326.0</td>\n",
       "      <td>...</td>\n",
       "      <td>112.760606</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.107509</td>\n",
       "      <td>0.321896</td>\n",
       "      <td>0.663132</td>\n",
       "      <td>0.014972</td>\n",
       "      <td>0.090509</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>K394220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5039</th>\n",
       "      <td>F</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15/09/97</td>\n",
       "      <td>37.433333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>CAT 200</td>\n",
       "      <td>ASAD90</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1169.400001</td>\n",
       "      <td>201.0</td>\n",
       "      <td>...</td>\n",
       "      <td>279.346320</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.130433</td>\n",
       "      <td>0.615895</td>\n",
       "      <td>0.346500</td>\n",
       "      <td>0.037605</td>\n",
       "      <td>0.127974</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>K192650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5040</th>\n",
       "      <td>F</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28/09/96</td>\n",
       "      <td>49.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CAT 100</td>\n",
       "      <td>CAS30</td>\n",
       "      <td>135.0</td>\n",
       "      <td>405.600000</td>\n",
       "      <td>124.0</td>\n",
       "      <td>...</td>\n",
       "      <td>170.946142</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.189112</td>\n",
       "      <td>0.555769</td>\n",
       "      <td>0.412716</td>\n",
       "      <td>0.031515</td>\n",
       "      <td>0.238615</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>K295600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5041</th>\n",
       "      <td>M</td>\n",
       "      <td>23.0</td>\n",
       "      <td>08/06/99</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CAT 200</td>\n",
       "      <td>BS110</td>\n",
       "      <td>566.0</td>\n",
       "      <td>2382.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>345.520741</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.112657</td>\n",
       "      <td>0.810121</td>\n",
       "      <td>0.162330</td>\n",
       "      <td>0.027548</td>\n",
       "      <td>0.043094</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>K366420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5042</th>\n",
       "      <td>M</td>\n",
       "      <td>46.0</td>\n",
       "      <td>01/03/98</td>\n",
       "      <td>31.866667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Play 100</td>\n",
       "      <td>S50</td>\n",
       "      <td>72.0</td>\n",
       "      <td>112.200000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>83.744194</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.205957</td>\n",
       "      <td>0.323250</td>\n",
       "      <td>0.664650</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.171451</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>K219850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5043</th>\n",
       "      <td>M</td>\n",
       "      <td>61.0</td>\n",
       "      <td>12/11/98</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CAT 100</td>\n",
       "      <td>S50</td>\n",
       "      <td>148.0</td>\n",
       "      <td>403.200000</td>\n",
       "      <td>187.0</td>\n",
       "      <td>...</td>\n",
       "      <td>166.503577</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.187393</td>\n",
       "      <td>0.553314</td>\n",
       "      <td>0.398930</td>\n",
       "      <td>0.047756</td>\n",
       "      <td>0.219329</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>K289480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5044 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender   Age Connect_Date      L_O_S  Dropped_Calls    tariff Handset  \\\n",
       "0         F  50.0     20/05/98  29.200000            2.0  Play 100   BS210   \n",
       "1         M  25.0     16/12/96  46.533333            1.0   CAT 100  ASAD90   \n",
       "2         F  46.0     27/08/97  38.066667            1.0    CAT 50    WC95   \n",
       "3         F  59.0     13/07/98  27.400000            1.0    CAT 50   BS110   \n",
       "4         F  25.0     08/01/99  21.433333            1.0  Play 300    WC95   \n",
       "...     ...   ...          ...        ...            ...       ...     ...   \n",
       "5039      F  16.0     15/09/97  37.433333            2.0   CAT 200  ASAD90   \n",
       "5040      F  29.0     28/09/96  49.166667            1.0   CAT 100   CAS30   \n",
       "5041      M  23.0     08/06/99  16.400000            0.0   CAT 200   BS110   \n",
       "5042      M  46.0     01/03/98  31.866667            2.0  Play 100     S50   \n",
       "5043      M  61.0     12/11/98  23.333333            0.0   CAT 100     S50   \n",
       "\n",
       "      Peak_calls_Sum  Peak_mins_Sum  OffPeak_calls_Sum  ...  Total_Cost  \\\n",
       "0               62.0     153.000000              185.0  ...  112.386773   \n",
       "1              146.0     718.800000               98.0  ...  221.546571   \n",
       "2              160.0     322.800000                7.0  ...  128.811484   \n",
       "3               84.0     317.400001               57.0  ...  111.419646   \n",
       "4               14.0     309.600000              326.0  ...  112.760606   \n",
       "...              ...            ...                ...  ...         ...   \n",
       "5039           151.0    1169.400001              201.0  ...  279.346320   \n",
       "5040           135.0     405.600000              124.0  ...  170.946142   \n",
       "5041           566.0    2382.000000                4.0  ...  345.520741   \n",
       "5042            72.0     112.200000               31.0  ...   83.744194   \n",
       "5043           148.0     403.200000              187.0  ...  166.503577   \n",
       "\n",
       "      Tariff_OK  average cost min  Peak ratio  OffPeak ratio  Weekend ratio  \\\n",
       "0            OK          0.150531    0.246536       0.706735       0.046729   \n",
       "1            OK          0.188988    0.780710       0.178886       0.040404   \n",
       "2            OK          0.239300    0.722633       0.277367       0.000000   \n",
       "3            OK          0.221467    0.662492       0.337508       0.000000   \n",
       "4            OK          0.107509    0.321896       0.663132       0.014972   \n",
       "...         ...               ...         ...            ...            ...   \n",
       "5039         OK          0.130433    0.615895       0.346500       0.037605   \n",
       "5040         OK          0.189112    0.555769       0.412716       0.031515   \n",
       "5041         OK          0.112657    0.810121       0.162330       0.027548   \n",
       "5042         OK          0.205957    0.323250       0.664650       0.012100   \n",
       "5043         OK          0.187393    0.553314       0.398930       0.047756   \n",
       "\n",
       "      Nat-InterNat Ratio  high Dropped calls  No Usage       id  \n",
       "0               0.203034                   F         F  K262360  \n",
       "1               0.273249                   F         F  K170160  \n",
       "2               0.205025                   F         F  K331610  \n",
       "3               0.050090                   F         F  K332460  \n",
       "4               0.090509                   F         F  K394220  \n",
       "...                  ...                 ...       ...      ...  \n",
       "5039            0.127974                   F         F  K192650  \n",
       "5040            0.238615                   F         F  K295600  \n",
       "5041            0.043094                   F         F  K366420  \n",
       "5042            0.171451                   F         F  K219850  \n",
       "5043            0.219329                   F         F  K289480  \n",
       "\n",
       "[5044 rows x 38 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7087197b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n3/j9s0z6s92fd1_xkmg3xk0twh0000gn/T/ipykernel_74929/2875930225.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlasso_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlasso_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[1;32m   2397\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2398\u001b[0m         data=None, **kwargs):\n\u001b[0;32m-> 2399\u001b[0;31m     return gca().bar(\n\u001b[0m\u001b[1;32m   2400\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2401\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2340\u001b[0m                 \u001b[0myerr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_dx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_yunits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2342\u001b[0;31m         x, height, width, y, linewidth, hatch = np.broadcast_arrays(\n\u001b[0m\u001b[1;32m   2343\u001b[0m             \u001b[0;31m# Make args iterable too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m             np.atleast_1d(x), height, width, y, linewidth, hatch)\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(subok, *args)\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_shape\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;31m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;31m# consistently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m     \u001b[0;31m# unfortunately, it cannot handle 32 or more arguments directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "lasso = Lasso(alpha=0.1)\n",
    "names =  X.drop(\"id\", axis=1).columns\n",
    "lasso_coef = lasso.fit(X_train, y_train).coef_\n",
    "plt.bar(names, lasso_coef)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090a5234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68888e11-748d-4034-9b2e-d5282345386f",
   "metadata": {},
   "source": [
    "## model 5: Gradient boosting [score: 2.292013; secondary score: 0.813553]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bc47a7ba-02af-4ba1-bc27-cbdb17a7778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install necessary functions\n",
    "#!pip install xgboost\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cb5fcee4-44f9-4136-8705-6fe1f15b1534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text features\n",
    "cats1 = X_train.select_dtypes(exclude=np.number).columns.tolist()\n",
    "cats2 = X_val.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "# Convert to Pandas category\n",
    "for col in cats1:\n",
    "   X_train[col] = X_train[col].astype('category')\n",
    "for col in cats2:\n",
    "   X_val[col] = X_val[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5f92ebc0-0f1c-4763-97a0-bbc19ffa0f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                     object\n",
       "Age                       float64\n",
       "Connect_Date               object\n",
       "L_O_S                     float64\n",
       "Dropped_Calls             float64\n",
       "tariff                     object\n",
       "Handset                    object\n",
       "Peak_calls_Sum            float64\n",
       "Peak_mins_Sum             float64\n",
       "OffPeak_calls_Sum         float64\n",
       "OffPeak_mins_Sum          float64\n",
       "Weekend_calls_Sum         float64\n",
       "Weekend_mins_Sum          float64\n",
       "International_mins_Sum    float64\n",
       "Nat_call_cost_Sum         float64\n",
       "AvePeak                   float64\n",
       "AveOffPeak                float64\n",
       "AveWeekend                float64\n",
       "National_calls            float64\n",
       "National mins             float64\n",
       "AveNational               float64\n",
       "All_calls_mins            float64\n",
       "Dropped_calls_ratio       float64\n",
       "Usage_Band                 object\n",
       "Mins_charge               float64\n",
       "call_cost_per_min         float64\n",
       "actual call cost          float64\n",
       "Total_call_cost           float64\n",
       "Total_Cost                float64\n",
       "Tariff_OK                  object\n",
       "average cost min          float64\n",
       "Peak ratio                float64\n",
       "OffPeak ratio             float64\n",
       "Weekend ratio             float64\n",
       "Nat-InterNat Ratio        float64\n",
       "high Dropped calls         object\n",
       "No Usage                   object\n",
       "id                         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the dtypes attribute\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "89187892-b721-4e7c-ae03-d498cc91517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regression matrices\n",
    "dtrain_clf_gb = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
    "dtest_clf_gb = xgb.DMatrix(encoded_test, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "311151b7-1384-4f3c-866e-c4f5787b553a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eta=0.1, eval_metric=None,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training\n",
    "#define hyperparameters\n",
    "\n",
    "params = {\"objective\": \"binary:logistic\", \"tree_method\": \"hist\"}\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(n_estimators=100, objective='binary:logistic', tree_method='hist', eta=0.1, max_depth=3, enable_categorical=True)\n",
    "xgb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6f0e5782-5151-4035-8dd2-254aed210229",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb_classifier.get_booster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a634663e-4c2c-47e4-bbbc-cec3df37ea37",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dtest_reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n3/j9s0z6s92fd1_xkmg3xk0twh0000gn/T/ipykernel_74929/538663800.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtest_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dtest_reg' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "preds = model.predict(dtest_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7d9e51b5-ab5b-4bf0-a910-3bb6197ef05c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n3/j9s0z6s92fd1_xkmg3xk0twh0000gn/T/ipykernel_74929/2132573334.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ID\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PRED\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model_Results_5.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "#to make it a CSV\n",
    "df_results = pd.DataFrame()\n",
    "df_results[\"ID\"] = idtest\n",
    "df_results[\"PRED\"] = preds\n",
    "df_results.to_csv(\"Model_Results_5.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a28447c-60c8-4071-8026-8771f22b0c04",
   "metadata": {},
   "source": [
    "### model 6: Gradient descent [score: 1.580501; secondary score: 0.410734]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "41d40d13-a33b-4680-ae39-1234631578f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.random.randn(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "642b8b65-0899-4794-a8d2-6c6fd9aea057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    " return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "517cd084-b380-4cbf-8fef-5502043bfa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the loss function\n",
    "def loss(theta, X, y):\n",
    " h = sigmoid(X.dot(theta)) \n",
    " return -np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a1ed6b26-e225-44df-8fe7-fd788eb904aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(theta, X, y, alpha, num_iterations): \n",
    "    for i in range(num_iterations):\n",
    "        h = sigmoid(X.dot(theta)) \n",
    "        gradient = X.T.dot(y - h) \n",
    "        theta -= alpha * gradient \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "433c03c5-5e6a-4a49-bc4c-30646c62bcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(theta, X): \n",
    "    h = sigmoid(X.dot(theta)) \n",
    "    y_pred = np.where(h >= 0.5, 1, 0) \n",
    "    return y_pred\n",
    "\n",
    "preds = predict(theta, encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "527106c0-ec56-4bdc-a26b-0c668b0492ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to make it a CSV\n",
    "df_results = pd.DataFrame()\n",
    "df_results[\"ID\"] = idtest\n",
    "df_results[\"PRED\"] = preds\n",
    "df_results.to_csv(\"Model_Results_6.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcedd40-6379-4eb5-ae5e-4840b84db2ef",
   "metadata": {},
   "source": [
    "## model 7: Bagging [score: 2.190216; secondary score: 0.7896]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "543e544e-90fb-40ac-835f-d01ac62f6543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary functions\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0d4e9fe4-f06b-4fcd-a25c-99a8b5258f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('classifier', DecisionTreeClassifier(random_state=42))])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#leanring\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cd0281d5-c89b-4e41-af97-4569fda7e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make prediction on the testing data\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "preds = pipeline.predict(encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ae0eecb9-ec4c-4bad-9606-db4c44fc5c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to make it a CSV\n",
    "df_results = pd.DataFrame()\n",
    "df_results[\"ID\"] = idtest\n",
    "df_results[\"PRED\"] = preds\n",
    "df_results.to_csv(\"Model_Results_7.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be15f981-5108-45f6-9d81-018257306334",
   "metadata": {},
   "source": [
    "## model 8: k-NN [score: 3.891976; secondary score: 0.78756]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f115e2b7-ca34-469a-899d-980851521b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary functions\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7e57f8cf-2377-435d-ac0a-94a194689950",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define accuracy\n",
    "neighbors = np.arange(1,9)\n",
    "train_accuracy =np.zeros(len(neighbors))\n",
    "val_accuracy = np.zeros(len(neighbors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "44a44434-3080-441f-9196-fe6803d9bf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "#establish the model\n",
    "for i,k in enumerate(neighbors):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    #Fit the model\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = knn.score(X_train, y_train)\n",
    "\n",
    "    #Compute accuracy on the test set\n",
    "    val_accuracy[i] = knn.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "34b23995-71b0-4058-8bbf-4660e6644fc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n3/j9s0z6s92fd1_xkmg3xk0twh0000gn/T/ipykernel_74929/2189006284.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'KNN accuracy with varying number of neighbors'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Testing Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_accuracy' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting to see the results\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title('KNN accuracy with varying number of neighbors',fontsize=20)\n",
    "plt.plot(neighbors, test_accuracy, label='Testing Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label='Training accuracy')\n",
    "plt.legend(prop={'size': 20})\n",
    "plt.xlabel('Number of neighbors',fontsize=20)\n",
    "plt.ylabel('Accuracy',fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5449b485-1dab-4bf2-b919-4e647d350907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#when n=5 tesing accurancy is higher\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Fit the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Compute accuracy on the training set\n",
    "train_accuracy[i] = knn.score(X_train, y_train)\n",
    "\n",
    "#Compute accuracy on the test set\n",
    "val_accuracy[i] = knn.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17b5f3e-7b0d-4786-b290-9035e7c4dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e243ac8d-5b79-4cea-ad27-41e11ba9e08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = knn.fit(X_train, y_train)\n",
    "\n",
    "preds = model.predict(encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafda132-ab34-4cc4-9775-159b245b8e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to make it a CSV\n",
    "df_results = pd.DataFrame()\n",
    "df_results[\"ID\"] = idtest\n",
    "df_results[\"PRED\"] = preds\n",
    "df_results.to_csv(\"Model_Results_8.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5097377f-1887-4685-bebd-b181c9a08e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#More to explore\n",
    "#PCA\n",
    "#Oversampling, undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab52a70a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28339037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a6f332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d3b18d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aaa0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036d5b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9913e96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbe2b985",
   "metadata": {},
   "source": [
    "# Work in progress 👇👇👇"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7a0015",
   "metadata": {},
   "source": [
    "# # Working to make the profit metric work in crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b09990b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "TypeError: Profit_top_k_1() missing 1 required positional argument: 'y_val'\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "TypeError: Profit_top_k_1() missing 1 required positional argument: 'y_val'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "### The challenge is to include the profit_top_K metrics in the crossvalidation. \n",
    "#For now I keep on getting Nan values but works when used sepratly \n",
    "\n",
    "\n",
    "\n",
    "def Profit_top_k_1(estimator, X_train, y_train):\n",
    "    k = 20\n",
    "    var = 'average cost min'\n",
    "    \n",
    "    estimator.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = estimator.predict(X_train)\n",
    "    \n",
    "    y_pred_proba = estimator.predict_proba(X_train)\n",
    "    y_pred_proba = [sublist[1] for sublist in y_pred_proba]\n",
    "\n",
    "    averagecostmin = X_val['average cost min']\n",
    "    \n",
    "    df_results = pd.DataFrame()\n",
    "    df_results['y_pred'] = y_pred\n",
    "    df_results['y_true'] = y_train\n",
    "    df_results['predict_proba'] = y_pred_proba\n",
    "    df_results['average cost min'] = list(averagecostmin)\n",
    "    \n",
    "    sorted_df = df_results.sort_values(by= \"predict_proba\", ascending = False)\n",
    "    sum = 0\n",
    "    for i in range(0, k):\n",
    "        if df_results['y_true'][i] == df_results['y_pred'][i]:\n",
    "            sum += df_results[var][i]\n",
    "            \n",
    "            \n",
    "    return sum\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "profit_top_k_scorer = make_scorer(Profit_top_k_1, greater_is_better=True) ##With make scrorer it didn't work\n",
    "\n",
    "cv_results_N = cross_val_score(knn, X_val, y_val,cv=2, scoring=profit_top_k_scorer)\n",
    "cv_results_N"
   ]
  },
  {
   "cell_type": "raw",
   "id": "196d1b47",
   "metadata": {},
   "source": [
    "In scikit's (0.18.1) documentation I find what follows a bit confusing. Seems that writing your own scoring function is doable in multiple ways. But what's the difference?\n",
    "\n",
    "GridSearchCV takes a scoring argument as a:\n",
    "\n",
    "scorer callable object / function with signature scorer(estimator, X, y)\n",
    "\n",
    "This option is supported also in model evaluation docs.\n",
    "\n",
    "Conversely, make_scorer wants a score_func as a:\n",
    "\n",
    "score function (or loss function) with signature score_func(y, y_pred, **kwargs)\n",
    "\n",
    "\n",
    "Somewhere I found : scikit-learn has different utility functions (precision_score, recall_score, accuracy_score etc) which can be used to directly specify the actual and predicted values and calculate the result. Even writing the custom scorer must use the actual and predicted values in most cases. So the signature has to be (y, y_pred, ...).\n",
    "\n",
    "Now, in techniques like GridSearch or RandomizedSearch, the score on the cross-validated data has to be automatically. As the estimator and X keeps changing (X changes due to cross-validation), so do the predicted values and corresponding actual values. So scorer(estimator, X, y) makes sense. Take the estimator and X, call estimator.predict(X) to get the predicted output, compare it with actual (y) and calculate result.\n",
    "\n",
    "What make_scorer() does is just return a pointer to the actual function which does all that what I described above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f61af712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.09899539, 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Profit_top_k_1(estimator, X_train, y_train):\n",
    "    k = 20\n",
    "    var = 'average cost min'\n",
    "    \n",
    "    estimator.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = estimator.predict(X_train)\n",
    "    \n",
    "    y_pred_proba = estimator.predict_proba(X_train)\n",
    "    y_pred_proba = [sublist[1] for sublist in y_pred_proba]\n",
    "\n",
    "    averagecostmin = X_train['average cost min']\n",
    "    \n",
    "    df_results = pd.DataFrame()\n",
    "    df_results['y_pred'] = y_pred\n",
    "    df_results['y_true'] = y_train\n",
    "    df_results['predict_proba'] = y_pred_proba\n",
    "    df_results['average cost min'] = list(averagecostmin)\n",
    "    \n",
    "    sorted_df = df_results.sort_values(by= \"predict_proba\", ascending = False)\n",
    "    #print (sorted_df)\n",
    "    #print (sorted_df['average cost min'].iloc[0])\n",
    "    sum = 0\n",
    "    for i in range(0, k):\n",
    "        if sorted_df['y_true'][i] == sorted_df['y_pred'][i]:\n",
    "            \n",
    "            sum += sorted_df['average cost min'].iloc[i]\n",
    "            #print (sum)\n",
    "            \n",
    "    return sum\n",
    "\n",
    "def dummy_scorer(estimator, X, y):   # Just to try the scroring \n",
    "    \n",
    "    return 1\n",
    "\n",
    "cv_results_N = cross_val_score(knn, X_train, y_train, cv=4, scoring=Profit_top_k_1)\n",
    "cv_results_N_2 = cross_val_score(logreg, X_train, y_train, cv=2, scoring=Profit_top_k_1)\n",
    "\n",
    "cv_results_N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "775674c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8471670515663705"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Profit_top_k_1(logreg, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "65d6603a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = {\"Logistic Regression\": logreg, \"Neural networks\": MLPClassifier(hidden_layer_sizes=(100,), )\n",
    ",\n",
    "          \"Decision Tree\": DecisionTreeClassifier()}\n",
    "\n",
    "\n",
    "classifiers = [('Logistic Regression', logreg), ('K Nearest Neighbours', knn), ('Classification Tree', clf)]\n",
    "\n",
    "\n",
    "results = []\n",
    "profit = []\n",
    "\n",
    "for model in models.values():\n",
    "    kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
    "    \n",
    "    \n",
    "    cv_results_N = cross_val_score(model, X_train, y_train, cv=kf, scoring=Profit_top_k_1)\n",
    "    \n",
    "    \n",
    "    results.append(cv_results_N)\n",
    "\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d268c77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
